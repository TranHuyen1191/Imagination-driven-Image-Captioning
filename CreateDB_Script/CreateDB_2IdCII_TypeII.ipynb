{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import clip\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_CLIP = 49407\n",
    "N_un = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations loaded: 100393\n"
     ]
    }
   ],
   "source": [
    "## Prepare the artemis dataset (merge it with the emotion-histograms.)\n",
    "df_full = pd.read_csv(f'../Dataset/ArtEmis/ArtEmis_IdC/ArtEmis_IdCI.csv')\n",
    "print('Annotations loaded:', len(df_full))\n",
    "df_full['distEmo'] = df_full['distEmo'].apply(literal_eval)\n",
    "df_full['distEmo'] = df_full['distEmo'].apply(lambda x: (np.array(x) / float(sum(x))).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_full['subject'] = df_full['subject'].apply(literal_eval)\n",
    "df_full['predicate'] = df_full['predicate'].apply(literal_eval)\n",
    "df_full['CLIP_tokens'] = df_full['CLIP_tokens'].apply(literal_eval)\n",
    "df_IdCII = pd.DataFrame(columns =df_full.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'honestly'], ['this', 'dog', 'honestly'], ['this', 'guy', \"'s\", 'face', 'is', 'so', 'cherubic', 'and', 'cute', 'he', 'honestly'], ['this', 'guy', \"'s\", 'spiked', 'up', 'hair', 'honestly'], ['this', 'guy', \"'s\", 'headdress', 'honestly']]\n",
      "[['reminds', 'me', 'of', 'the', 'kiddie', 'pool', 'area', 'at', 'my', 'local', 'community', 'pool', 'everyone', 'is', 'frolicking', 'around', 'naked', 'and', 'no', 'one', 'knows', 'what', 'is', 'going', 'on'], ['reminds', 'me', 'of', 'chewbacca', 'the', 'star', 'wars', 'character', 'they', 'share', 'the', 'same', 'unruly', 'brown', 'fur', 'and', 'beady', 'black', 'eyes'], ['looks', 'like', 'a', 'baby', 'wearing', 'a', 'mustache', 'on', 'halloween'], ['reminds', 'me', 'of', 'a', 'cockatoo'], ['looks', 'like', 'a', 'lampshade', 'with', 'a', 'black', 'sheet', 'over', 'it', 'reminds', 'me', 'of', 'when', 'i', 'played', 'dress', 'up', 'as', 'a', 'kid']]\n",
      "<|startoftext|>this honestly looks like a man that is dressed in a woman 's clothes that is trying to play a joke on someone <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>this honestly reminds me of the kiddie pool area at my local community pool everyone is frolicking around naked and no one knows what is going on <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>this honestly reminds me of chewbacca the star wars character they share the same unruly brown fur and beady black eyes <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>this honestly looks like a baby wearing a mustache on halloween <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>this honestly reminds me of a cockatoo <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>this honestly looks like a lampshade with a black sheet over it reminds me of when i played dress up as a kid <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "## Create unnatural captions for the training set\n",
    "df = df_full[df_full.split=='train'].copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Encode tokens using CLIP tokenizer\n",
    "subject_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['subject']]\n",
    "predicate_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['predicate']]\n",
    "df['subject_CLIP_tokens'] = subject_CLIP_tokens\n",
    "df['predicate_CLIP_tokens'] = predicate_CLIP_tokens\n",
    "df['captSet_CLIP_tokens'] = None\n",
    "\n",
    "for painting,stimuli in df.groupby(['painting']):\n",
    "    for index, row in stimuli.iterrows():\n",
    "        painting = row['painting']\n",
    "        subject_CLIP_tokens = row['subject_CLIP_tokens']\n",
    "        CLIP_tokens = row['CLIP_tokens']\n",
    "        set_sameStyle = df[df.painting != painting]\n",
    "        set_sameStyle.reset_index(inplace=True, drop=True)\n",
    "        cnts_sameTokens = []\n",
    "        for other_subject_CLIP_tokens in set_sameStyle['subject_CLIP_tokens']:\n",
    "            cnts_sameTokens.append(len(set(subject_CLIP_tokens) & set(other_subject_CLIP_tokens)))\n",
    "\n",
    "        idx_sel_predicates = sorted(range(len(cnts_sameTokens)), key=lambda i: cnts_sameTokens[i])[-N_un:]\n",
    "        idx_sel_predicates.reverse() #From the most overlapped one\n",
    "        sel_predicates = set_sameStyle['predicate_CLIP_tokens'][idx_sel_predicates].to_list()\n",
    "        new_sentences = []\n",
    "        new_sentences.append(CLIP_tokens)\n",
    "        len_subject = subject_CLIP_tokens.index(eos_token_CLIP)\n",
    "\n",
    "        for sel_predicate in sel_predicates:\n",
    "            sent = subject_CLIP_tokens[:len_subject] + sel_predicate[1:]\n",
    "            sent = sent[:len(CLIP_tokens)]\n",
    "            new_sentences.append(sent)\n",
    "        row['captSet_CLIP_tokens'] = new_sentences\n",
    "        df_IdCII = df_IdCII.append(row)\n",
    "        \n",
    "# See some examples\n",
    "print(set_sameStyle['subject'][idx_sel_predicates].to_list())\n",
    "print(set_sameStyle['predicate'][idx_sel_predicates].to_list())\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()\n",
    "print(_tokenizer.decode(new_sentences[0]))\n",
    "print(_tokenizer.decode(new_sentences[1]))\n",
    "print(_tokenizer.decode(new_sentences[2]))\n",
    "print(_tokenizer.decode(new_sentences[3]))\n",
    "print(_tokenizer.decode(new_sentences[4]))\n",
    "print(_tokenizer.decode(new_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'girls', 'in', 'this', 'picture'], ['a', 'lovely', 'day', 'of', 'gathering', 'flowers', 'the', 'girls'], ['this', 'makes', 'me', 'feel', 'happy', 'cause', 'the', 'girls'], ['the', 'colors', 'of', 'the', 'girls', 'cheeks'], ['love', 'the', 'use', 'of', 'green', 'in', 'this', 'painting', 'the', 'girls']]\n",
      "[['seem', 'to', 'be', 'bursting', 'with', 'life', 'and', 'appreciation', 'for', 'one', 'another'], ['look', 'like', 'they', 'are', 'enjoying', 'themselves', 'and', 'the', 'yellow', 'flowers', 'brighten', 'the', 'mood', 'even', 'more'], ['look', 'like', 'they', 'are', 'ready', 'for', 'a', 'party'], ['remind', 'me', 'of', 'childhood'], ['look', 'like', 'they', 'are', 'enjoying', 'a', 'nice', 'spring', 'day']]\n",
      "<|startoftext|>the girls look like slaves or peasants yet the colors and tone are happy <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>the girls seem to be bursting with life and appreciation for one another <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>the girls look like they are enjoying themselves and the yellow flowers brighten the mood even more <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>the girls look like they are ready for a party <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>the girls remind me of childhood <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>the girls look like they are enjoying a nice spring day <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "## Create unnatural captions for the validation set\n",
    "df = df_full[df_full.split=='val'].copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Encode tokens using CLIP tokenizer\n",
    "subject_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['subject']]\n",
    "predicate_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['predicate']]\n",
    "df['subject_CLIP_tokens'] = subject_CLIP_tokens\n",
    "df['predicate_CLIP_tokens'] = predicate_CLIP_tokens\n",
    "df['captSet_CLIP_tokens'] = None\n",
    "\n",
    "for painting,stimuli in df.groupby(['painting']):\n",
    "    for index, row in stimuli.iterrows():\n",
    "        painting = row['painting']\n",
    "        subject_CLIP_tokens = row['subject_CLIP_tokens']\n",
    "        CLIP_tokens = row['CLIP_tokens']\n",
    "        set_sameStyle = df[df.painting != painting]\n",
    "        set_sameStyle.reset_index(inplace=True, drop=True)\n",
    "        cnts_sameTokens = []\n",
    "        for other_subject_CLIP_tokens in set_sameStyle['subject_CLIP_tokens']:\n",
    "            cnts_sameTokens.append(len(set(subject_CLIP_tokens) & set(other_subject_CLIP_tokens)))\n",
    "\n",
    "        idx_sel_predicates = sorted(range(len(cnts_sameTokens)), key=lambda i: cnts_sameTokens[i])[-N_un:]\n",
    "        idx_sel_predicates.reverse() #From the most overlapped one\n",
    "        sel_predicates = set_sameStyle['predicate_CLIP_tokens'][idx_sel_predicates].to_list()\n",
    "        new_sentences = []\n",
    "        new_sentences.append(CLIP_tokens)\n",
    "        len_subject = subject_CLIP_tokens.index(eos_token_CLIP)\n",
    "\n",
    "        for sel_predicate in sel_predicates:\n",
    "            sent = subject_CLIP_tokens[:len_subject] + sel_predicate[1:]\n",
    "            sent = sent[:len(CLIP_tokens)]\n",
    "            new_sentences.append(sent)\n",
    "        row['captSet_CLIP_tokens'] = new_sentences\n",
    "        df_IdCII = df_IdCII.append(row)\n",
    "        \n",
    "# See some examples\n",
    "print(set_sameStyle['subject'][idx_sel_predicates].to_list())\n",
    "print(set_sameStyle['predicate'][idx_sel_predicates].to_list())\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()\n",
    "print(_tokenizer.decode(new_sentences[0]))\n",
    "print(_tokenizer.decode(new_sentences[1]))\n",
    "print(_tokenizer.decode(new_sentences[2]))\n",
    "print(_tokenizer.decode(new_sentences[3]))\n",
    "print(_tokenizer.decode(new_sentences[4]))\n",
    "print(_tokenizer.decode(new_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'picture', 'makes', 'me', 'feel', 'sad', 'because', 'she', 'does', 'not', 'have', 'any', 'expression', 'her', 'eyes', 'look', 'lost', 'i', 'almost'], ['i', 'feel', 'sad', 'because', 'this'], ['i', 'feel', 'sad', 'because', 'the', 'workers', 'in', 'this', 'picture', 'look', 'older', 'and', 'tired', 'does', 'not'], ['this', 'makes', 'me', 'feel', 'sad', 'because', 'i', 'feel'], ['i', 'really', 'like', 'the', 'color', 'combination', 'of', 'this', 'artwork', 'it', 'does', 'make', 'me', 'feel', 'sad', 'and', 'scared', 'because', 'it']]\n",
      "[['feel', 'like', 'she', 'is', 'submissive', 'and', 'being', 'controlled'], ['looks', 'like', 'a', 'painting', 'of', 'an', 'impoverished', 'shantytown'], ['look', 'like', 'a', 'healthy', 'situation'], ['as', 'though', 'i', 'am', 'grieving', 'along', 'with', 'the', 'other', 'people'], ['looks', 'like', 'someone', 'is', 'being', 'stabbed', 'to', 'death']]\n",
      "<|startoftext|>i feel sad because this lady look like she resting from a hard days work <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>i feel sad because this lady feel like she is submissive and being controlled <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>i feel sad because this lady looks like a painting of an impoverished shantytown <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>i feel sad because this lady look like a healthy situation <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>i feel sad because this lady as though i am grieving along with the other people <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<|startoftext|>i feel sad because this lady looks like someone is being stabbed to death <|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "## Create unnatural captions for the test set\n",
    "df = df_full[df_full.split=='test'].copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Encode tokens using CLIP tokenizer\n",
    "subject_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['subject']]\n",
    "predicate_CLIP_tokens = [clip.tokenize(' '.join(utter)).squeeze().tolist() for utter in df['predicate']]\n",
    "df['subject_CLIP_tokens'] = subject_CLIP_tokens\n",
    "df['predicate_CLIP_tokens'] = predicate_CLIP_tokens\n",
    "df['captSet_CLIP_tokens'] = None\n",
    "\n",
    "for painting,stimuli in df.groupby(['painting']):\n",
    "    for index, row in stimuli.iterrows():\n",
    "        painting = row['painting']\n",
    "        subject_CLIP_tokens = row['subject_CLIP_tokens']\n",
    "        CLIP_tokens = row['CLIP_tokens']\n",
    "        set_sameStyle = df[df.painting != painting]\n",
    "        set_sameStyle.reset_index(inplace=True, drop=True)\n",
    "        cnts_sameTokens = []\n",
    "        for other_subject_CLIP_tokens in set_sameStyle['subject_CLIP_tokens']:\n",
    "            cnts_sameTokens.append(len(set(subject_CLIP_tokens) & set(other_subject_CLIP_tokens)))\n",
    "\n",
    "        idx_sel_predicates = sorted(range(len(cnts_sameTokens)), key=lambda i: cnts_sameTokens[i])[-N_un:]\n",
    "        idx_sel_predicates.reverse() #From the most overlapped one\n",
    "        sel_predicates = set_sameStyle['predicate_CLIP_tokens'][idx_sel_predicates].to_list()\n",
    "        new_sentences = []\n",
    "        new_sentences.append(CLIP_tokens)\n",
    "        len_subject = subject_CLIP_tokens.index(eos_token_CLIP)\n",
    "\n",
    "        for sel_predicate in sel_predicates:\n",
    "            sent = subject_CLIP_tokens[:len_subject] + sel_predicate[1:]\n",
    "            sent = sent[:len(CLIP_tokens)]\n",
    "            new_sentences.append(sent)\n",
    "        row['captSet_CLIP_tokens'] = new_sentences\n",
    "        df_IdCII = df_IdCII.append(row)\n",
    "        \n",
    "# See some examples\n",
    "print(set_sameStyle['subject'][idx_sel_predicates].to_list())\n",
    "print(set_sameStyle['predicate'][idx_sel_predicates].to_list())\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()\n",
    "print(_tokenizer.decode(new_sentences[0]))\n",
    "print(_tokenizer.decode(new_sentences[1]))\n",
    "print(_tokenizer.decode(new_sentences[2]))\n",
    "print(_tokenizer.decode(new_sentences[3]))\n",
    "print(_tokenizer.decode(new_sentences[4]))\n",
    "print(_tokenizer.decode(new_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IdCII.reset_index(drop=True,inplace=True)\n",
    "df_IdCII.to_csv( '../Dataset/ArtEmis/ArtEmis_IdC/ArtEmis_IdCII.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch13",
   "language": "python",
   "name": "pytorch13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
