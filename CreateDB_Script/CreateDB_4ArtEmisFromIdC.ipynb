{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8647ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Code adapted from the data preprocessing code of the ArtEmis paper.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Combine, clean, pre-process ArtEmis annotations.\n",
    "The MIT License (MIT)\n",
    "Originally created by Panos Achlioptas at 6/17/20, for Python 3.x\n",
    "Copyright (c) 2021 Panos Achlioptas (pachlioptas@gmail.com) & Stanford Geometric Computing Lab\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "import argparse\n",
    "import pprint\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import pdb\n",
    "random_seed = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fa2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454684\n"
     ]
    }
   ],
   "source": [
    "## load source dataset\n",
    "source_data_csv = '../Dataset/ArtEmis/OriginalArtEmis/artemis_dataset_full.csv'\n",
    "df = pd.read_csv(source_data_csv)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a29121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with available input features of M2 model: 80924\n"
     ]
    }
   ],
   "source": [
    "#Load a list of images with input features of M2 model provided by ArtEmis paper\n",
    "with open('../Dataset/ArtEmis/OriginalArtEmis/list_avai_imgId.pkl','rb') as file: \n",
    "    avai_imgID = pickle.load(file)\n",
    "with open('../Dataset/ArtEmis/OriginalArtEmis/wikiart_split.pkl','rb') as file:\n",
    "    paints_ids_dict = dict(pickle.load(file))\n",
    "paints_ids_dict_ids = list(paints_ids_dict.values())\n",
    "paints_ids_dict_imgfiles = list(paints_ids_dict.keys())\n",
    "avai_imgfiles = []\n",
    "for imgid in avai_imgID:\n",
    "    avai_imgfiles.append(paints_ids_dict_imgfiles[imgid])\n",
    "print(f\"Number of images with available input features of M2 model: {len(avai_imgfiles)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3442f472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymSpell spell-checker loaded: True\n",
      "Loading glove word embeddings.\n",
      "Done. 400000 words loaded.\n",
      "Updating Glove vocabulary with *valid* ArtEmis words that are missing from it.\n",
      "tokens not in Glove/Manual vocabulary: 662\n",
      "454684\n"
     ]
    }
   ],
   "source": [
    "## Create utterance_spelled\n",
    "from artemis.language.basics import tokenize_and_spell\n",
    "glove_file = '../Dataset/ArtEmis/OriginalArtEmis/glove.6B.100d.vocabulary.txt'\n",
    "freq_file = '../Dataset/ArtEmis/OriginalArtEmis/symspell_frequency_dictionary_en_82_765.txt'\n",
    "missed_tokens = tokenize_and_spell(df, glove_file, freq_file, nltk.word_tokenize, spell_check=True)\n",
    "print('tokens not in Glove/Manual vocabulary:', len(missed_tokens))\n",
    "print(len(df.utterance_spelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181c5427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453525\n"
     ]
    }
   ],
   "source": [
    "too_long_cap = df.tokens_len > 63\n",
    "df = df[~too_long_cap]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cafe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete images whose input features of M2 model are not provided\n",
    "img_files = '/'+df.art_style+'/'+df.painting\n",
    "sel_img_idx = []\n",
    "for img_file in img_files.tolist():\n",
    "    sel_img_idx.append(img_file in avai_imgfiles)\n",
    "df = df[sel_img_idx]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6ca6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of literal captions: 338742\n",
      "Number of images that has literal captions: 79384\n"
     ]
    }
   ],
   "source": [
    "## Detect literal captions by excluding Imagination-driven captions\n",
    "# List of keywords\n",
    "keywords_2tokens = {'looks like','look like','look as','looks as','reminds me','remind me',\n",
    "                       'is like','is likely','are like','are likely','think of','thinks of',\n",
    "                       'as if','as though','feel like','feels like','shaped like', 'shapes like', 'shape like',\n",
    "                       'calm like','looks likely','look likely',\n",
    "                       'seems like','seem like','seems as', 'seem as',\n",
    "                    }\n",
    "\n",
    "keywords_3tokens = {'looks almost like','look almost like','is almost as','are almost as','seems to be', 'seem to be'}\n",
    "keywords_1tokens = {'resemble','resembling'}\n",
    "keywords_1tokens_spell = []\n",
    "keywords_2tokens_spell = []\n",
    "keywords_3tokens_spell = []\n",
    "for keyword in keywords_1tokens:\n",
    "    keywords_1tokens_spell.append(((keyword.split(' '))))\n",
    "for keyword in keywords_2tokens:\n",
    "    keywords_2tokens_spell.append(((keyword.split(' '))))\n",
    "for keyword in keywords_3tokens:\n",
    "    keywords_3tokens_spell.append(((keyword.split(' '))))\n",
    "\n",
    "subjects = []\n",
    "subjects_maxLen = 0\n",
    "predicates = []\n",
    "predicates_maxLen = 0\n",
    "for index,tokens_encoded in enumerate(df['tokens']):\n",
    "    subject = None\n",
    "    predicate = None\n",
    "    for i,currToken in enumerate(tokens_encoded):\n",
    "        currToken = tokens_encoded[i:i+1]\n",
    "        if currToken in keywords_1tokens_spell:\n",
    "            if len(tokens_encoded[i:])>=2 and len(tokens_encoded[:i])>=1:\n",
    "                subject = tokens_encoded[:i]\n",
    "                predicate = tokens_encoded[i:]\n",
    "                if subjects_maxLen < len(subject):\n",
    "                    subjects_maxLen = len(subject)\n",
    "                if predicates_maxLen < len(predicate):\n",
    "                    predicates_maxLen = len(predicate)\n",
    "                break # Stop at the first keyword in the sentence\n",
    "            elif len(tokens_encoded[:i]) ==0:\n",
    "                subject = ['it']\n",
    "                predicate = tokens_encoded[i:]\n",
    "                if subjects_maxLen < len(subject):\n",
    "                    subjects_maxLen = len(subject)\n",
    "                if predicates_maxLen < len(predicate):\n",
    "                    predicates_maxLen = len(predicate)\n",
    "                break # Stop at the first keyword in the sentence\n",
    "        if i >= 1:\n",
    "            contToken = tokens_encoded[i-1:i+1]\n",
    "            if contToken in keywords_2tokens_spell:\n",
    "                if len(tokens_encoded[i:])>=2  and len(tokens_encoded[:i-1])>=1:\n",
    "                    subject = tokens_encoded[:i-1]\n",
    "                    predicate = tokens_encoded[i-1:]\n",
    "                    if subjects_maxLen < len(subject):\n",
    "                        subjects_maxLen = len(subject)\n",
    "                    if predicates_maxLen < len(predicate):\n",
    "                        predicates_maxLen = len(predicate)\n",
    "                    break # Stop at the first keyword in the sentence\n",
    "                elif len(tokens_encoded[:i-1]) ==0:\n",
    "                    subject = ['it']\n",
    "                    predicate = tokens_encoded[i-1:]\n",
    "                    if subjects_maxLen < len(subject):\n",
    "                        subjects_maxLen = len(subject)\n",
    "                    if predicates_maxLen < len(predicate):\n",
    "                        predicates_maxLen = len(predicate)\n",
    "                    break # Stop at the first keyword in the sentence\n",
    "        if i >= 2:\n",
    "            contToken = tokens_encoded[i-2:i+1]\n",
    "            if contToken in keywords_3tokens_spell:\n",
    "                if len(tokens_encoded[i:])>=2   and len(tokens_encoded[:i-2])>=1:\n",
    "                    subject = tokens_encoded[:i-2]\n",
    "                    predicate = tokens_encoded[i-2:]\n",
    "                    if subjects_maxLen < len(subject):\n",
    "                        subjects_maxLen = len(subject)\n",
    "                    if predicates_maxLen < len(predicate):\n",
    "                        predicates_maxLen = len(predicate)\n",
    "                    break # Stop at the first keyword in the sentence\n",
    "                elif len(tokens_encoded[:i-2]) ==0:\n",
    "                    subject = ['it']\n",
    "                    predicate = tokens_encoded[i-2:]\n",
    "                    if subjects_maxLen < len(subject):\n",
    "                        subjects_maxLen = len(subject)\n",
    "                    if predicates_maxLen < len(predicate):\n",
    "                        predicates_maxLen = len(predicate)\n",
    "                    break # Stop at the first keyword in the sentence\n",
    "    subjects.append(subject)\n",
    "    predicates.append(predicate)\n",
    "\n",
    "df['subject']=subjects\n",
    "df['predicate']=predicates\n",
    "df_LC = df[[subject == None for subject in df.subject]].copy()\n",
    "df = None\n",
    "df_LC.reset_index(drop=True, inplace=True)\n",
    "df_LC['img_id'] = [row.art_style + '/'+row.painting for _,row in df_LC.iterrows()]\n",
    "img_ids_LC = df_LC['img_id'].unique()\n",
    "print(\"Number of literal captions:\",len(df_LC))\n",
    "print(\"Number of images that has literal captions:\",len(img_ids_LC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8440946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdC dataset: Number of training captions: 75509\n",
      "IdC dataset: Number of val captions: 9000\n",
      "IdC dataset: Number of test captions: 15884\n",
      "IdC dataset: Total number of captions: 100393\n",
      "######\n",
      "IdC dataset: Number of training images: 51210\n",
      "IdC dataset: Number of val images: 3000\n",
      "IdC dataset: Number of test images: 2497\n",
      "IdC dataset: Total number of images: 56707\n"
     ]
    }
   ],
   "source": [
    "## load IdCI dataset\n",
    "IdCI_data_csv = '../Dataset/ArtEmis/ArtEmis_IdC/ArtEmis_IdCI.csv'\n",
    "df_IdC = pd.read_csv(IdCI_data_csv)\n",
    "df_IdC.subject = df_IdC.subject.apply(literal_eval)\n",
    "df_IdC.predicate = df_IdC.predicate.apply(literal_eval)\n",
    "df_IdC.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "df_IdC['img_id'] = [row.art_style + '/'+row.painting for _,row in df_IdC.iterrows()]\n",
    "img_ids_IdC_train = df_IdC[df_IdC.split=='train']['img_id'].to_list()\n",
    "img_ids_IdC_test = df_IdC[df_IdC.split=='test']['img_id'].to_list()\n",
    "img_ids_IdC_val = df_IdC[df_IdC.split=='val']['img_id'].to_list()\n",
    "img_ids_IdC = img_ids_IdC_train + img_ids_IdC_test + img_ids_IdC_val\n",
    "print(\"IdC dataset: Number of training captions:\",len(img_ids_IdC_train))\n",
    "print(\"IdC dataset: Number of val captions:\",len(img_ids_IdC_val))\n",
    "print(\"IdC dataset: Number of test captions:\",len(img_ids_IdC_test))\n",
    "print(\"IdC dataset: Total number of captions:\",len(img_ids_IdC))\n",
    "\n",
    "print(\"######\")\n",
    "img_ids_IdC_train = list(set(img_ids_IdC_train))\n",
    "img_ids_IdC_test = list(set(img_ids_IdC_test))\n",
    "img_ids_IdC_val = list(set(img_ids_IdC_val))\n",
    "img_ids_IdC = list(set(img_ids_IdC))\n",
    "print(\"IdC dataset: Number of training images:\",len(img_ids_IdC_train))\n",
    "print(\"IdC dataset: Number of val images:\",len(img_ids_IdC_val))\n",
    "print(\"IdC dataset: Number of test images:\",len(img_ids_IdC_test))\n",
    "print(\"IdC dataset: Total number of images:\",len(img_ids_IdC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38895196",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pd.merge(df_IdC,df_LC, on=\"utterance\",how='inner')) == 0 # No overlapping between df_IdC and df_LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8408121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = pd.concat([df_IdC,df_LC])\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "merged['repetition'] =  merged.groupby('img_id')['img_id'].transform('count')\n",
    "assert len(merged[merged.split.isnull()]) == len(df_LC)\n",
    "df_LC = merged[merged.split.isnull()].copy()\n",
    "df_LC.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d9b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images NOT IN IdC: 22818\n",
      "Number of captions of images NOT IN IdC: 115009\n"
     ]
    }
   ],
   "source": [
    "df_notInIdC = df_LC[[img_id not in img_ids_IdC for img_id in df_LC.img_id.tolist()]]\n",
    "df_notInIdC.reset_index(drop=True, inplace=True)\n",
    "img_ids_notInIdC = df_notInIdC.img_id.unique()\n",
    "print(\"Number of images NOT IN IdC:\",len(img_ids_notInIdC))\n",
    "print(\"Number of captions of images NOT IN IdC:\",len(df_notInIdC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f54c38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19940\n"
     ]
    }
   ],
   "source": [
    "## Splits to train, val, test sets\n",
    "train = []\n",
    "rest = []\n",
    "for img_id,g in df_notInIdC.groupby('img_id'):\n",
    "    repetition = g.repetition.tolist()[0]\n",
    "    if repetition <5:\n",
    "        train.append(img_id)\n",
    "    else:\n",
    "        rest.append(img_id)\n",
    "print(len(rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644d5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(img_ids_notInIdC) - len(rest)- len(train) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b6bc5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotInIdC dataset: Number of training images: 16818\n",
      "NotInIdC dataset: Number of val images: 3000\n",
      "NotInIdC dataset: Number of test images: 3000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "val_size  =  3000\n",
    "test_size =  3000\n",
    "  \n",
    "rest.sort()\n",
    "rest, val = train_test_split(rest, test_size=val_size, random_state=random_seed)\n",
    "train_2, test = train_test_split(rest, test_size=test_size, random_state=random_seed)\n",
    "train = train + train_2\n",
    "assert len(set(test).intersection(set(train))) == 0\n",
    "assert len(set(val).intersection(set(train))) == 0\n",
    "assert len(set(test).intersection(set(val))) == 0\n",
    "print(\"NotInIdC dataset: Number of training images:\",len(train))\n",
    "print(\"NotInIdC dataset: Number of val images:\",len(val))\n",
    "print(\"NotInIdC dataset: Number of test images:\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c82b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset: Number of training images: 68028\n",
      "Whole dataset: Number of val images: 6000\n",
      "Whole dataset: Number of test images: 5497\n"
     ]
    }
   ],
   "source": [
    "train = train  + img_ids_IdC_train\n",
    "val = val  + img_ids_IdC_val\n",
    "test = test  + img_ids_IdC_test\n",
    "\n",
    "print(\"Whole dataset: Number of training images:\",len(train))\n",
    "print(\"Whole dataset: Number of val images:\",len(val))\n",
    "print(\"Whole dataset: Number of test images:\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10a193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(merged.img_id.unique()) - len(train)- len(val)- len(test) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05dc518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348197\n",
      "32011\n",
      "58927\n"
     ]
    }
   ],
   "source": [
    "merged['split'] =  ['train' if uni_id in train  else 'val' if uni_id in val  else 'test' for uni_id in merged.img_id ]\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "print(len(merged[merged.split == 'train']))\n",
    "print(len(merged[merged.split == 'val']) )\n",
    "print(len(merged[merged.split == 'test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a240ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[['art_style', 'painting', 'emotion','utterance', 'subject', 'predicate', 'split','img_id']].copy()\n",
    "merged.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6877788",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['repetition'] =  merged.groupby('img_id')['img_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa31a416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymSpell spell-checker loaded: True\n",
      "Loading glove word embeddings.\n",
      "Done. 400000 words loaded.\n",
      "Updating Glove vocabulary with *valid* ArtEmis words that are missing from it.\n",
      "tokens not in Glove/Manual vocabulary: 637\n",
      "439135\n"
     ]
    }
   ],
   "source": [
    "## Create utterance_spelled\n",
    "missed_tokens = tokenize_and_spell(merged, glove_file, freq_file, nltk.word_tokenize, spell_check=True)\n",
    "print('tokens not in Glove/Manual vocabulary:', len(missed_tokens))\n",
    "print(len(merged.utterance_spelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733303f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_style</th>\n",
       "      <th>painting</th>\n",
       "      <th>emotion</th>\n",
       "      <th>utterance</th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>split</th>\n",
       "      <th>img_id</th>\n",
       "      <th>repetition</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_len</th>\n",
       "      <th>utterance_spelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post_Impressionism</td>\n",
       "      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>This woman has really knotty hands which makes...</td>\n",
       "      <td>[this, woman, has, really, knotty, hands, whic...</td>\n",
       "      <td>[look, like, she, has, arthritis]</td>\n",
       "      <td>train</td>\n",
       "      <td>Post_Impressionism/vincent-van-gogh_portrait-o...</td>\n",
       "      <td>10</td>\n",
       "      <td>[this, woman, has, really, knotty, hands, whic...</td>\n",
       "      <td>14</td>\n",
       "      <td>this woman has really knotty hands which makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post_Impressionism</td>\n",
       "      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n",
       "      <td>awe</td>\n",
       "      <td>She looks like a lady from that past that migh...</td>\n",
       "      <td>[she]</td>\n",
       "      <td>[looks, like, a, lady, from, that, past, that,...</td>\n",
       "      <td>train</td>\n",
       "      <td>Post_Impressionism/vincent-van-gogh_portrait-o...</td>\n",
       "      <td>10</td>\n",
       "      <td>[she, looks, like, a, lady, from, that, past, ...</td>\n",
       "      <td>33</td>\n",
       "      <td>she looks like a lady from that past that migh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>willard-metcalf_havana-harbor</td>\n",
       "      <td>contentment</td>\n",
       "      <td>The red of the flowers pop off the page, it is...</td>\n",
       "      <td>[the, red, of, the, flowers, pop, off, the, pa...</td>\n",
       "      <td>[looks, like, a, wonderful, place, to, vacatio...</td>\n",
       "      <td>train</td>\n",
       "      <td>Impressionism/willard-metcalf_havana-harbor</td>\n",
       "      <td>6</td>\n",
       "      <td>[the, red, of, the, flowers, pop, off, the, pa...</td>\n",
       "      <td>24</td>\n",
       "      <td>the red of the flowers pop off the page it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>robert-campin_werl-altarpiece-st-barbara-1438</td>\n",
       "      <td>amusement</td>\n",
       "      <td>The books seems to be drawn in a confusing way...</td>\n",
       "      <td>[the, books]</td>\n",
       "      <td>[seems, to, be, drawn, in, a, confusing, way, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>Northern_Renaissance/robert-campin_werl-altarp...</td>\n",
       "      <td>7</td>\n",
       "      <td>[the, books, seems, to, be, drawn, in, a, conf...</td>\n",
       "      <td>26</td>\n",
       "      <td>the books seems to be drawn in a confusing way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Realism</td>\n",
       "      <td>theodor-severin-kittelsen_kveld-paa-soletunet-...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>The two run down houses look like they have se...</td>\n",
       "      <td>[the, two, run, down, houses]</td>\n",
       "      <td>[look, like, they, have, seen, better, days]</td>\n",
       "      <td>train</td>\n",
       "      <td>Realism/theodor-severin-kittelsen_kveld-paa-so...</td>\n",
       "      <td>7</td>\n",
       "      <td>[the, two, run, down, houses, look, like, they...</td>\n",
       "      <td>12</td>\n",
       "      <td>the two run down houses look like they have se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439130</th>\n",
       "      <td>Cubism</td>\n",
       "      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n",
       "      <td>something else</td>\n",
       "      <td>The interlocking mechanical shapes fitting tog...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>Cubism/willi-baumeister_machine-man-with-spira...</td>\n",
       "      <td>44</td>\n",
       "      <td>[the, interlocking, mechanical, shapes, fittin...</td>\n",
       "      <td>10</td>\n",
       "      <td>the interlocking mechanical shapes fitting tog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439131</th>\n",
       "      <td>Cubism</td>\n",
       "      <td>gino-severini_a-dancer-1</td>\n",
       "      <td>awe</td>\n",
       "      <td>the collection and collage of different colors...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>Cubism/gino-severini_a-dancer-1</td>\n",
       "      <td>47</td>\n",
       "      <td>[the, collection, and, collage, of, different,...</td>\n",
       "      <td>12</td>\n",
       "      <td>the collection and collage of different colors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439132</th>\n",
       "      <td>Romanticism</td>\n",
       "      <td>ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>awe</td>\n",
       "      <td>The peaceful reflections of the moonlight on t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>train</td>\n",
       "      <td>Romanticism/ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>8</td>\n",
       "      <td>[the, peaceful, reflections, of, the, moonligh...</td>\n",
       "      <td>14</td>\n",
       "      <td>the peaceful reflections of the moonlight on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439133</th>\n",
       "      <td>Romanticism</td>\n",
       "      <td>ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>excitement</td>\n",
       "      <td>I can imagine the sailors resting this peacefu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>train</td>\n",
       "      <td>Romanticism/ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>8</td>\n",
       "      <td>[i, can, imagine, the, sailors, resting, this,...</td>\n",
       "      <td>13</td>\n",
       "      <td>i can imagine the sailors resting this peacefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439134</th>\n",
       "      <td>Romanticism</td>\n",
       "      <td>ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>contentment</td>\n",
       "      <td>The steep mountains and the moonlight provide ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>train</td>\n",
       "      <td>Romanticism/ivan-aivazovsky_sea-at-night-1861</td>\n",
       "      <td>8</td>\n",
       "      <td>[the, steep, mountains, and, the, moonlight, p...</td>\n",
       "      <td>15</td>\n",
       "      <td>the steep mountains and the moonlight provide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439135 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   art_style  \\\n",
       "0         Post_Impressionism   \n",
       "1         Post_Impressionism   \n",
       "2              Impressionism   \n",
       "3       Northern_Renaissance   \n",
       "4                    Realism   \n",
       "...                      ...   \n",
       "439130                Cubism   \n",
       "439131                Cubism   \n",
       "439132           Romanticism   \n",
       "439133           Romanticism   \n",
       "439134           Romanticism   \n",
       "\n",
       "                                                 painting         emotion  \\\n",
       "0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...         sadness   \n",
       "1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...             awe   \n",
       "2                           willard-metcalf_havana-harbor     contentment   \n",
       "3           robert-campin_werl-altarpiece-st-barbara-1438       amusement   \n",
       "4       theodor-severin-kittelsen_kveld-paa-soletunet-...         sadness   \n",
       "...                                                   ...             ...   \n",
       "439130  willi-baumeister_machine-man-with-spiral-turn-...  something else   \n",
       "439131                           gino-severini_a-dancer-1             awe   \n",
       "439132                  ivan-aivazovsky_sea-at-night-1861             awe   \n",
       "439133                  ivan-aivazovsky_sea-at-night-1861      excitement   \n",
       "439134                  ivan-aivazovsky_sea-at-night-1861     contentment   \n",
       "\n",
       "                                                utterance  \\\n",
       "0       This woman has really knotty hands which makes...   \n",
       "1       She looks like a lady from that past that migh...   \n",
       "2       The red of the flowers pop off the page, it is...   \n",
       "3       The books seems to be drawn in a confusing way...   \n",
       "4       The two run down houses look like they have se...   \n",
       "...                                                   ...   \n",
       "439130  The interlocking mechanical shapes fitting tog...   \n",
       "439131  the collection and collage of different colors...   \n",
       "439132  The peaceful reflections of the moonlight on t...   \n",
       "439133  I can imagine the sailors resting this peacefu...   \n",
       "439134  The steep mountains and the moonlight provide ...   \n",
       "\n",
       "                                                  subject  \\\n",
       "0       [this, woman, has, really, knotty, hands, whic...   \n",
       "1                                                   [she]   \n",
       "2       [the, red, of, the, flowers, pop, off, the, pa...   \n",
       "3                                            [the, books]   \n",
       "4                           [the, two, run, down, houses]   \n",
       "...                                                   ...   \n",
       "439130                                               None   \n",
       "439131                                               None   \n",
       "439132                                               None   \n",
       "439133                                               None   \n",
       "439134                                               None   \n",
       "\n",
       "                                                predicate  split  \\\n",
       "0                       [look, like, she, has, arthritis]  train   \n",
       "1       [looks, like, a, lady, from, that, past, that,...  train   \n",
       "2       [looks, like, a, wonderful, place, to, vacatio...  train   \n",
       "3       [seems, to, be, drawn, in, a, confusing, way, ...  train   \n",
       "4            [look, like, they, have, seen, better, days]  train   \n",
       "...                                                   ...    ...   \n",
       "439130                                               None   test   \n",
       "439131                                               None   test   \n",
       "439132                                               None  train   \n",
       "439133                                               None  train   \n",
       "439134                                               None  train   \n",
       "\n",
       "                                                   img_id  repetition  \\\n",
       "0       Post_Impressionism/vincent-van-gogh_portrait-o...          10   \n",
       "1       Post_Impressionism/vincent-van-gogh_portrait-o...          10   \n",
       "2             Impressionism/willard-metcalf_havana-harbor           6   \n",
       "3       Northern_Renaissance/robert-campin_werl-altarp...           7   \n",
       "4       Realism/theodor-severin-kittelsen_kveld-paa-so...           7   \n",
       "...                                                   ...         ...   \n",
       "439130  Cubism/willi-baumeister_machine-man-with-spira...          44   \n",
       "439131                    Cubism/gino-severini_a-dancer-1          47   \n",
       "439132      Romanticism/ivan-aivazovsky_sea-at-night-1861           8   \n",
       "439133      Romanticism/ivan-aivazovsky_sea-at-night-1861           8   \n",
       "439134      Romanticism/ivan-aivazovsky_sea-at-night-1861           8   \n",
       "\n",
       "                                                   tokens  tokens_len  \\\n",
       "0       [this, woman, has, really, knotty, hands, whic...          14   \n",
       "1       [she, looks, like, a, lady, from, that, past, ...          33   \n",
       "2       [the, red, of, the, flowers, pop, off, the, pa...          24   \n",
       "3       [the, books, seems, to, be, drawn, in, a, conf...          26   \n",
       "4       [the, two, run, down, houses, look, like, they...          12   \n",
       "...                                                   ...         ...   \n",
       "439130  [the, interlocking, mechanical, shapes, fittin...          10   \n",
       "439131  [the, collection, and, collage, of, different,...          12   \n",
       "439132  [the, peaceful, reflections, of, the, moonligh...          14   \n",
       "439133  [i, can, imagine, the, sailors, resting, this,...          13   \n",
       "439134  [the, steep, mountains, and, the, moonlight, p...          15   \n",
       "\n",
       "                                        utterance_spelled  \n",
       "0       this woman has really knotty hands which makes...  \n",
       "1       she looks like a lady from that past that migh...  \n",
       "2       the red of the flowers pop off the page it is ...  \n",
       "3       the books seems to be drawn in a confusing way...  \n",
       "4       the two run down houses look like they have se...  \n",
       "...                                                   ...  \n",
       "439130  the interlocking mechanical shapes fitting tog...  \n",
       "439131  the collection and collage of different colors...  \n",
       "439132  the peaceful reflections of the moonlight on t...  \n",
       "439133  i can imagine the sailors resting this peacefu...  \n",
       "439134  the steep mountains and the moonlight provide ...  \n",
       "\n",
       "[439135 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62090511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images having only 4 captions: 45\n",
      "Number of test images having <4 captions: 0\n",
      "Number of test images having >=5 captions: 5452\n"
     ]
    }
   ],
   "source": [
    "## CHECK test images has at least 4 captions\n",
    "assert not any(np.array(merged[merged.split == 'test'].repetition.tolist()) <4)\n",
    "assert not any(np.array(merged[merged.split == 'val'].repetition.tolist()) <3)\n",
    "temp = merged[merged.split == 'test'].copy()\n",
    "temp2 = temp[temp.repetition==4]\n",
    "print(\"Number of test images having only 4 captions:\",len(temp2.img_id.unique()))\n",
    "temp2 = temp[temp.repetition<4]\n",
    "print(\"Number of test images having <4 captions:\",len(temp2.img_id.unique()))\n",
    "temp2 = temp[temp.repetition>=5]\n",
    "print(\"Number of test images having >=5 captions:\",len(temp2.img_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4e44bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['art_style', 'painting', 'emotion', 'utterance', 'subject', 'predicate',\n",
       "       'split', 'img_id', 'repetition', 'tokens', 'tokens_len',\n",
       "       'utterance_spelled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b213a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a vocabulary with 15018 tokens\n"
     ]
    }
   ],
   "source": [
    "# Make a word-vocabulary based on training data\n",
    "from artemis.utils.vocabulary import build_vocab\n",
    "min_word_freq = 5\n",
    "train_tokens = merged[merged.split =='train']['tokens']\n",
    "vocab = build_vocab(train_tokens, min_word_freq)\n",
    "print(f'Using a vocabulary with {len(vocab)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48df3b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encode tokens as ints\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "max_len = max(merged.tokens_len)\n",
    "merged['tokens_encoded'] = merged.tokens.apply(lambda x: vocab.encode(x, max_len))\n",
    "merged['subject_encoded'] = merged.subject.apply(lambda x: vocab.encode(x, max_len) if isinstance(x, list) else None)\n",
    "merged['predicate_encoded'] = merged.predicate.apply(lambda x: vocab.encode(x, max_len) if isinstance(x, list) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0814e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode tokens using CLIP tokenizer\n",
    "import clip \n",
    "merged['CLIP_tokens'] = [clip.tokenize(' '.join(utter.split(' ')[:62])).squeeze().tolist() for utter in merged['utterance_spelled']]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "907bb1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ARTEMIS_EMOTIONS = ['amusement', 'awe', 'contentment', 'excitement',\n",
    "                    'anger', 'disgust',  'fear', 'sadness','something else']\n",
    "\n",
    "EMOTION_TO_IDX = {e: i for i, e in enumerate(ARTEMIS_EMOTIONS)}\n",
    "no_emo = len(ARTEMIS_EMOTIONS)\n",
    "IDX_TO_EMOTION = {EMOTION_TO_IDX[e]: e for e in EMOTION_TO_IDX}\n",
    "merged['emotion_label'] = merged.emotion.apply(lambda emotion: EMOTION_TO_IDX[emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d223000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separately the grouped utterances of each stimulus\n",
    "def group_gt_annotations(df, vocab):\n",
    "    \"\"\" Group the annotations according to the underlying artwork/stimulus.\n",
    "    :param preprocessed_dataframe: dataframe carrying ArtEmis annotations, spell-checked, with splits etc.\n",
    "    :param vocab: the corresponding Vocabulary object\n",
    "    :return: dictionary, carrying for each split (tran/test/val) a dataframe that has for each artwork all its collected\n",
    "        annotations grouped.\n",
    "    \"\"\"\n",
    "    results = dict()\n",
    "    for split, g in df.groupby('split'): # group-by split\n",
    "        g.reset_index(inplace=True, drop=True)\n",
    "        g = g.groupby(['art_style', 'painting']) # group-by stimulus\n",
    "\n",
    "        # group utterances / emotions\n",
    "        # a) before \"vocabularization\" (i.e., raw)\n",
    "        refs_pre_vocab_grouped = g['utterance_spelled'].apply(list).reset_index(name='references_pre_vocab')\n",
    "        \n",
    "        tokens_grouped = g['tokens_encoded'].apply(list).reset_index(name='tokens_encoded')\n",
    "        #print(len(tokens_grouped.iloc[2]['tokens_encoded']))\n",
    "        assert all(tokens_grouped['painting'] == refs_pre_vocab_grouped['painting'])\n",
    "\n",
    "        # decode these tokens back to strings and name them \"references\"\n",
    "        tokens_grouped['tokens_encoded'] =\\\n",
    "            tokens_grouped['tokens_encoded'].apply(lambda x: [vocab.decode_print(sent) for sent in x])\n",
    "        tokens_grouped = tokens_grouped.rename(columns={'tokens_encoded': 'references'})\n",
    "\n",
    "        result = pd.merge(refs_pre_vocab_grouped, tokens_grouped)\n",
    "        result.reset_index(drop=True, inplace=True)\n",
    "        results[split] = result\n",
    "    return results\n",
    "\n",
    "groups = group_gt_annotations(merged, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb5f07c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-utterances kept: 439135\n",
      "vocab size: 15018\n",
      "Maximum number of tokens per caption is 63\n",
      "Minimum number of tokens per caption is 1\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle\n",
    "def pickle_data(file_name, *args):\n",
    "    \"\"\"Using (c)Pickle to save multiple python objects in a single file.\n",
    "    \"\"\"\n",
    "    out_file = open(file_name, 'wb')\n",
    "    cPickle.dump(len(args), out_file, protocol=2)\n",
    "    for item in args:\n",
    "        cPickle.dump(item, out_file, protocol=2)\n",
    "    out_file.close()\n",
    "    \n",
    "\n",
    "merged.reset_index(drop=True,inplace=True)\n",
    "merged.to_csv(f'../Dataset/ArtEmis/ArtEmis/ArtEmis.csv', index=False)\n",
    "vocab.save(f'../Dataset/ArtEmis/ArtEmis/ArtEmis_Vocab.pkl')\n",
    "pickle_data(f'../Dataset/ArtEmis/ArtEmis/Artemis_GT.pkl', groups)\n",
    "print('n-utterances kept:', len(merged))\n",
    "print('vocab size:', len(vocab))\n",
    "print(f'Maximum number of tokens per caption is {max_len}')\n",
    "print(f'Minimum number of tokens per caption is {min(merged.tokens_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d60604e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  captions per image:  2  images with 2  captions\n",
      "2  captions per image:  30  images with 60  captions\n",
      "3  captions per image:  574  images with 1722  captions\n",
      "4  captions per image:  7425  images with 29700  captions\n",
      ">=5 captions per image:  71494  images with 407651  captions\n",
      "Total images: 79525\n",
      "Total captions: 439135\n"
     ]
    }
   ],
   "source": [
    "### Extract number of images having the number of captions = noCap\n",
    "for noCap in range(1,5):\n",
    "    cnt = 0\n",
    "    cntexp = 0\n",
    "    for name, group in merged.groupby('img_id'):\n",
    "        #print(group)\n",
    "        #break\n",
    "        if group.repetition.iloc[0] ==noCap:\n",
    "            #print(group.freq)\n",
    "            cnt= cnt + 1\n",
    "            cntexp += len(group)\n",
    "    print(noCap,\" captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "cnt = 0\n",
    "cntexp = 0\n",
    "for name, group in merged.groupby('img_id'):\n",
    "    if group.repetition.iloc[0] >=5:\n",
    "        #print(group.freq)\n",
    "        cnt= cnt + 1\n",
    "        cntexp += len(group)\n",
    "print(\">=5 captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "\n",
    "print('Total images:',len(merged.img_id.unique()))\n",
    "print('Total captions:',len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82baa049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  captions per image:  0  images with 0  captions\n",
      "2  captions per image:  0  images with 0  captions\n",
      "3  captions per image:  0  images with 0  captions\n",
      "4  captions per image:  45  images with 180  captions\n",
      ">=5 captions per image:  5452  images with 58747  captions\n",
      "Numer of test images: 5497\n",
      "Numer of test captions: 58927\n"
     ]
    }
   ],
   "source": [
    "### Extract number of images having the number of captions = noCap for only testset\n",
    "for noCap in range(1,5):\n",
    "    cnt = 0\n",
    "    cntexp = 0\n",
    "    for name, group in merged[merged.split == 'test'].groupby('img_id'):\n",
    "        #print(group)\n",
    "        #break\n",
    "        if group.repetition.iloc[0] ==noCap:\n",
    "            #print(group.freq)\n",
    "            cnt= cnt + 1\n",
    "            cntexp += len(group)\n",
    "    print(noCap,\" captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "cnt = 0\n",
    "cntexp = 0\n",
    "for name, group in merged[merged.split == 'test'].groupby('img_id'):\n",
    "    if group.repetition.iloc[0] >=5:\n",
    "        #print(group.freq)\n",
    "        cnt= cnt + 1\n",
    "        cntexp += len(group)\n",
    "print(\">=5 captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "\n",
    "print('Numer of test images:',len(merged[merged.split == 'test'].img_id.unique()))\n",
    "print('Numer of test captions:',len(merged[merged.split == 'test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "import base64\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "import nltk\n",
    "data_dir = '../Dataset/ArtEmis/ArtEmis'\n",
    "\n",
    "## Load dataset\n",
    "file_name = f'ArtEmis.csv'\n",
    "merged = pd.read_csv(osp.join(data_dir, file_name))\n",
    "print(f'Loaded {len(merged)} captions!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
