{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8647ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Code adapted from the data preprocessing code of the ArtEmis paper.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Combine, clean, pre-process ArtEmis annotations.\n",
    "The MIT License (MIT)\n",
    "Originally created by Panos Achlioptas at 6/17/20, for Python 3.x\n",
    "Copyright (c) 2021 Panos Achlioptas (pachlioptas@gmail.com) & Stanford Geometric Computing Lab\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "import argparse\n",
    "import pprint\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import pdb\n",
    "from model.vocabulary import Vocabulary\n",
    "random_seed = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fa2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huyentran/anaconda3/envs/pytorch13/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (4,5,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439135\n"
     ]
    }
   ],
   "source": [
    "## load  dataset\n",
    "vocab = Vocabulary.load('../Dataset/ArtEmis/ArtEmis/ArtEmis_Vocab.pkl')\n",
    "data_csv = '../Dataset/ArtEmis/ArtEmis/ArtEmis.csv'\n",
    "df = pd.read_csv(data_csv)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24019eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.where(pd.notnull(df), 'None')\n",
    "df.tokens_encoded = df.tokens_encoded.apply(literal_eval)\n",
    "df.subject_encoded = df.subject_encoded.apply(literal_eval)\n",
    "df['IdCflag'] = [0 if x == None else 1 for x in df.subject_encoded.tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f471d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train captions: 348197\n",
      "Number of train images: 68028\n",
      "Number of val captions: 32011\n",
      "Number of val images: 6000\n",
      "Number of testing captions: 58927\n",
      "Number of testing images: 5497\n"
     ]
    }
   ],
   "source": [
    "df_ = df[df['split']=='train']\n",
    "print(\"Number of train captions:\",len(df_))\n",
    "print(\"Number of train images:\",len(set(df_.img_id.tolist())))\n",
    "df_ = df[df['split']=='val'].copy()\n",
    "print(\"Number of val captions:\",len(df_))\n",
    "print(\"Number of val images:\",len(set(df_.img_id.tolist())))\n",
    "df_ = df[df['split']=='test']\n",
    "df_.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of testing captions:\",len(df_))\n",
    "print(\"Number of testing images:\",len(set(df_.img_id.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f554fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train literal captions: 272688\n",
      "Number of train images with literal captions: 68014\n",
      "Number of val literal captions: 23011\n",
      "Number of val images with literal captions: 5996\n",
      "Number of testing literal captions: 43043\n",
      "Number of testing images with literal captions: 5374\n",
      "Number of testing literal captions with repetition>=4: 41128\n",
      "Number of testing images with >=4 literal captions: 4019\n",
      "Number of literal captions (excluding test captions with repetition <4): 336827\n"
     ]
    }
   ],
   "source": [
    "df_LC = df[df.IdCflag == 0].copy()\n",
    "df_LC.reset_index(drop=True, inplace=True)\n",
    "df_LC_train = df_LC[df_LC['split']=='train'].copy()\n",
    "print(\"Number of train literal captions:\",len(df_LC_train))\n",
    "print(\"Number of train images with literal captions:\",len(set(df_LC_train.img_id.tolist())))\n",
    "df_LC_val = df_LC[df_LC['split']=='val'].copy()\n",
    "print(\"Number of val literal captions:\",len(df_LC_val))\n",
    "print(\"Number of val images with literal captions:\",len(set(df_LC_val.img_id.tolist())))\n",
    "df_LC = df_LC[df_LC['split']=='test']\n",
    "df_LC.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of testing literal captions:\",len(df_LC))\n",
    "print(\"Number of testing images with literal captions:\",len(set(df_LC.img_id.tolist())))\n",
    "df_LC['repetition'] =  df_LC.groupby('img_id')['img_id'].transform('count')\n",
    "df_LC = df_LC[df_LC['repetition']>=4]\n",
    "df_LC.reset_index(drop=True, inplace=True)\n",
    "assert len(df_LC[df_LC['repetition']<4]) == 0\n",
    "print(\"Number of testing literal captions with repetition>=4:\",len(df_LC))\n",
    "print(\"Number of testing images with >=4 literal captions:\",len(set(df_LC.img_id.tolist())))\n",
    "df_LC = pd.concat([df_LC,df_LC_train,df_LC_val])\n",
    "df_LC.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of literal captions (excluding test captions with repetition <4):\",len(df_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fb0521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train Id-captions: 75509\n",
      "Number of train images with Id-captions: 51210\n",
      "Number of val Id-captions: 9000\n",
      "Number of val images with Id-captions: 3000\n",
      "Number of testing Id-captions: 15884\n",
      "Number of testing images with Id-captions: 2497\n",
      "Number of testing Id-captions with repetition>=4: 15884\n",
      "Number of testing images with >=4 Id-captions: 2497\n",
      "Number of Id-captions (excluding test captions with repetition <4): 100393\n"
     ]
    }
   ],
   "source": [
    "df_IdC = df[df.IdCflag == 1].copy()\n",
    "df_IdC.reset_index(drop=True, inplace=True)\n",
    "df_IdC_train = df_IdC[df_IdC['split']=='train'].copy()\n",
    "print(\"Number of train Id-captions:\",len(df_IdC_train))\n",
    "print(\"Number of train images with Id-captions:\",len(set(df_IdC_train.img_id.tolist())))\n",
    "df_IdC_val = df_IdC[df_IdC['split']=='val'].copy()\n",
    "print(\"Number of val Id-captions:\",len(df_IdC_val))\n",
    "print(\"Number of val images with Id-captions:\",len(set(df_IdC_val.img_id.tolist())))\n",
    "df_IdC = df_IdC[df_IdC['split']=='test']\n",
    "df_IdC.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of testing Id-captions:\",len(df_IdC))\n",
    "print(\"Number of testing images with Id-captions:\",len(set(df_IdC.img_id.tolist())))\n",
    "df_IdC['repetition'] =  df_IdC.groupby('img_id')['img_id'].transform('count')\n",
    "assert len(df_IdC[df_IdC['repetition']<4]) == 0\n",
    "print(\"Number of testing Id-captions with repetition>=4:\",len(df_IdC))\n",
    "print(\"Number of testing images with >=4 Id-captions:\",len(set(df_IdC.img_id.tolist())))\n",
    "df_IdC = pd.concat([df_IdC,df_IdC_train,df_IdC_val])\n",
    "df_IdC.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of Id-captions (excluding test captions with repetition <4):\",len(df_IdC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d223000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separately the grouped utterances of each stimulus\n",
    "def group_gt_annotations(df, vocab):\n",
    "    \"\"\" Group the annotations according to the underlying artwork/stimulus.\n",
    "    :param preprocessed_dataframe: dataframe carrying ArtEmis annotations, spell-checked, with splits etc.\n",
    "    :param vocab: the corresponding Vocabulary object\n",
    "    :return: dictionary, carrying for each split (tran/test/val) a dataframe that has for each artwork all its collected\n",
    "        annotations grouped.\n",
    "    \"\"\"\n",
    "    results = dict()\n",
    "    for split, g in df.groupby('split'): # group-by split\n",
    "        g.reset_index(inplace=True, drop=True)\n",
    "        g = g.groupby(['art_style', 'painting']) # group-by stimulus\n",
    "\n",
    "        # group utterances / emotions\n",
    "        # a) before \"vocabularization\" (i.e., raw)\n",
    "        refs_pre_vocab_grouped = g['utterance_spelled'].apply(list).reset_index(name='references_pre_vocab')\n",
    "        \n",
    "        tokens_grouped = g['tokens_encoded'].apply(list).reset_index(name='tokens_encoded')\n",
    "        #print(len(tokens_grouped.iloc[2]['tokens_encoded']))\n",
    "        assert all(tokens_grouped['painting'] == refs_pre_vocab_grouped['painting'])\n",
    "\n",
    "        # decode these tokens back to strings and name them \"references\"\n",
    "        tokens_grouped['tokens_encoded'] =\\\n",
    "            tokens_grouped['tokens_encoded'].apply(lambda x: [vocab.decode_print(sent) for sent in x])\n",
    "        tokens_grouped = tokens_grouped.rename(columns={'tokens_encoded': 'references'})\n",
    "\n",
    "        result = pd.merge(refs_pre_vocab_grouped, tokens_grouped)\n",
    "        result.reset_index(drop=True, inplace=True)\n",
    "        results[split] = result\n",
    "    return results\n",
    "\n",
    "from six.moves import cPickle\n",
    "def pickle_data(file_name, *args):\n",
    "    \"\"\"Using (c)Pickle to save multiple python objects in a single file.\n",
    "    \"\"\"\n",
    "    out_file = open(file_name, 'wb')\n",
    "    cPickle.dump(len(args), out_file, protocol=2)\n",
    "    for item in args:\n",
    "        cPickle.dump(item, out_file, protocol=2)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5f07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = group_gt_annotations(df_LC, vocab)\n",
    "pickle_data(f'../Dataset/ArtEmis/ArtEmis/Artemis_GT_LC.pkl', groups)\n",
    "groups = group_gt_annotations(df_IdC, vocab)\n",
    "pickle_data(f'../Dataset/ArtEmis/ArtEmis/Artemis_GT_IdC.pkl', groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d60604e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  captions per image:  2  images with 2  captions\n",
      "2  captions per image:  24  images with 35  captions\n",
      "3  captions per image:  562  images with 1291  captions\n",
      "4  captions per image:  7428  images with 22757  captions\n",
      ">=5 captions per image:  70013  images with 312742  captions\n",
      "Total images: 78029\n",
      "Total captions: 336827\n"
     ]
    }
   ],
   "source": [
    "### Extract number of images having the number of captions = noCap\n",
    "for noCap in range(1,5):\n",
    "    cnt = 0\n",
    "    cntexp = 0\n",
    "    for name, group in df_LC.groupby('img_id'):\n",
    "        #print(group)\n",
    "        #break\n",
    "        if group.repetition.iloc[0] ==noCap:\n",
    "            #print(group.freq)\n",
    "            cnt= cnt + 1\n",
    "            cntexp += len(group)\n",
    "    print(noCap,\" captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "cnt = 0\n",
    "cntexp = 0\n",
    "for name, group in df_LC.groupby('img_id'):\n",
    "    if group.repetition.iloc[0] >=5:\n",
    "        #print(group.freq)\n",
    "        cnt= cnt + 1\n",
    "        cntexp += len(group)\n",
    "print(\">=5 captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "\n",
    "print('Total images:',len(df_LC.img_id.unique()))\n",
    "print('Total captions:',len(df_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82baa049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  captions per image:  0  images with 0  captions\n",
      "2  captions per image:  19  images with 25  captions\n",
      "3  captions per image:  327  images with 431  captions\n",
      "4  captions per image:  6217  images with 12775  captions\n",
      ">=5 captions per image:  50144  images with 87162  captions\n",
      "Total images: 56707\n",
      "Total captions: 100393\n"
     ]
    }
   ],
   "source": [
    "### Extract number of images having the number of captions = noCap\n",
    "for noCap in range(1,5):\n",
    "    cnt = 0\n",
    "    cntexp = 0\n",
    "    for name, group in df_IdC.groupby('img_id'):\n",
    "        #print(group)\n",
    "        #break\n",
    "        if group.repetition.iloc[0] ==noCap:\n",
    "            #print(group.freq)\n",
    "            cnt= cnt + 1\n",
    "            cntexp += len(group)\n",
    "    print(noCap,\" captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "cnt = 0\n",
    "cntexp = 0\n",
    "for name, group in df_IdC.groupby('img_id'):\n",
    "    if group.repetition.iloc[0] >=5:\n",
    "        #print(group.freq)\n",
    "        cnt= cnt + 1\n",
    "        cntexp += len(group)\n",
    "print(\">=5 captions per image: \",cnt,\" images with\",cntexp,\" captions\")\n",
    "\n",
    "print('Total images:',len(df_IdC.img_id.unique()))\n",
    "print('Total captions:',len(df_IdC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
