{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060cc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\"\n",
    "#### Code adapted from the source code of ArtEmis dataset paper\n",
    "####################################################################\n",
    "Training a neural-speaker.\n",
    "\n",
    "The MIT License (MIT)\n",
    "Originally created at 6/16/20, for Python 3.x\n",
    "Copyright (c) 2021 Panos Achlioptas (ai.stanford.edu/~optas) & Stanford Geometric Computing Lab\n",
    "####################################################################\n",
    "\"\"\"\n",
    "import pprint\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from torch import nn\n",
    "from termcolor import colored\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    \n",
    "from model.argument import parse_test_speaker_arguments,set_seed\n",
    "from model.datasets_v2 import preprocess_dataset\n",
    "from model.func_train_v2 import load_state_dicts\n",
    "from model.func_test_v3 import read_saved_args,grounding_dataset_per_image_dummy,versatile_caption_sampler\n",
    "from model.func_test_v3 import pickle_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3d67cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters Specified:\n",
      "{'drop_bigrams': True,\n",
      " 'drop_unk': True,\n",
      " 'gpu': '0',\n",
      " 'img_dir': '',\n",
      " 'max_utterance_len': None,\n",
      " 'out_file': 'output/Ours_ArtEmis/CLIPViTB16_woSG/fullDB_test.pkl',\n",
      " 'out_file_full': None,\n",
      " 'random_seed': 2021,\n",
      " 'sampling_config_file': 'None',\n",
      " 'speaker_checkpoint': 'output/Ours_ArtEmis/CLIPViTB16_woSG/checkpoints/best_model.pt',\n",
      " 'speaker_saved_args': 'output/Ours_ArtEmis/CLIPViTB16_woSG/config.json.txt',\n",
      " 'split': 'test'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelname = 'CLIPViTB16_woSG' \n",
    "\n",
    "model_dir = f'output/Ours_ArtEmis/{modelname}'\n",
    "outputfile = osp.join(model_dir,'fullDB_test.pkl')\n",
    "\n",
    "args_val = parse_test_speaker_arguments(\n",
    "        ['-speaker-saved-args',osp.join(model_dir,'config.json.txt'),\n",
    "         '-speaker-checkpoint',osp.join(model_dir,'checkpoints/best_model.pt'),#best_model.pt model_epoch_20.pt last_model\n",
    "         '-out-file',outputfile,\n",
    "         '-img-dir', '',\n",
    "         '--sampling-config-file', None,\n",
    "         '--split', 'test',\n",
    "         '--gpu','0']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5088945f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FreezeCase': 0,\n",
      " 'accum_iter': 2,\n",
      " 'backboneVisEnc': 'ViTB16',\n",
      " 'batch_size': 32,\n",
      " 'context_length': 65,\n",
      " 'data_dir': '../Dataset/ArtEmis/ArtEmis',\n",
      " 'debug': False,\n",
      " 'droprate': 0.0,\n",
      " 'gpu': '0',\n",
      " 'image_resolution': 224,\n",
      " 'img_dir': '../Dataset/ArtEmis/ArtEmis/../OriginalArtEmis/Images/CLIP_224',\n",
      " 'lr_others': 0.001,\n",
      " 'lr_patience': 2,\n",
      " 'lr_textEnc': 0.001,\n",
      " 'lr_visEnc': 1e-07,\n",
      " 'max_epochs': 200,\n",
      " 'modeltype': 'woSG',\n",
      " 'no_transform': True,\n",
      " 'output_dir': 'output/Ours_ArtEmis/CLIPViTB16_woSG',\n",
      " 'random_seed': 2021,\n",
      " 'save_each_epoch': False,\n",
      " 'train_patience': 5,\n",
      " 'transformer_heads': 8,\n",
      " 'transformer_layers': 8,\n",
      " 'use_timestamp': False,\n",
      " 'use_vocabFAM': True,\n",
      " 'vocab_size': 15018}\n"
     ]
    }
   ],
   "source": [
    "args = read_saved_args(args_val.speaker_saved_args)\n",
    "modeltype = args.modeltype \n",
    "use_vocabFAM = args.use_vocabFAM\n",
    "print(pprint.pformat(vars(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acceaa23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huyentran/anaconda3/envs/pytorch13/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (4,5,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 439135 captions!!!\n"
     ]
    }
   ],
   "source": [
    "## Load dataset\n",
    "file_name = 'ArtEmis.csv'\n",
    "df = pd.read_csv(osp.join(args.data_dir, file_name))\n",
    "df = df.where(pd.notnull(df), 'None')\n",
    "if args.random_seed != -1:\n",
    "    set_seed(args.random_seed)\n",
    "if args.debug:\n",
    "    df = df.sample(50)\n",
    "print(f'Loaded {len(df)} captions!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eadb8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.img_dir = '../Dataset/ArtEmis/OriginalArtEmis/wikiart' \n",
    "if 'CLIP' in modelname:\n",
    "    img_transform = Compose([\n",
    "        Resize(args.image_resolution, interpolation=BICUBIC),\n",
    "        CenterCrop(args.image_resolution),\n",
    "        lambda image: image.convert(\"RGB\"),\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "elif 'INRN34' in modelname:\n",
    "    image_net_mean = [0.485, 0.456, 0.406]\n",
    "    image_net_std = [0.229, 0.224, 0.225]\n",
    "    resample_method = Image.LANCZOS\n",
    "    normalize = Normalize(mean=image_net_mean, std=image_net_std)\n",
    "    img_transform = Compose([Resize((args.image_resolution, args.image_resolution), resample_method),ToTensor(),normalize])\n",
    "elif 'INViTB16'in modelname:\n",
    "    img_transform = Compose([\n",
    "        Resize(size=248, interpolation=BICUBIC, max_size=None, antialias=None),\n",
    "        CenterCrop(size=(224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize((0.5000, 0.5000, 0.5000), (0.5000, 0.5000, 0.5000))])\n",
    "else:\n",
    "    raise ValueError(f\"Do not support model = {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc921a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'full': \n",
    "    from model.model_v2 import fullArc as idcmodel\n",
    "elif modeltype == 'woSG': \n",
    "    from model.model_v2 import woSGArc as idcmodel \n",
    "elif modeltype == '1Gen': \n",
    "    from model.model_v2 import oneGenArc as idcmodel \n",
    "else:\n",
    "    raise ValueError(f\"Do not support modeltype = {modeltype}!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d123f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 30, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_vocabFAM:\n",
    "    from model.vocabulary import Vocabulary\n",
    "    from model.func_test_v2 import get_highest_prob_capt as get_highest_prob_capt\n",
    "    vocab = Vocabulary.load(osp.join(args.data_dir, 'ArtEmis_Vocab.pkl'))\n",
    "    eos_token = 2\n",
    "    sos_token = 1\n",
    "    and_token = vocab('and')\n",
    "    unk_token  = vocab.unk\n",
    "else: # Use original vocabulary of CLIP\n",
    "    from model.clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "    from model.func_test_v2 import get_highest_prob_capt_CLIP as get_highest_prob_capt\n",
    "    vocab = _Tokenizer()\n",
    "    eos_token = args.vocab_size-1 # eos_token is the last number\n",
    "    sos_token = args.vocab_size-2 #sos_token is the last second number\n",
    "    and_token = vocab.encode('and')[0]\n",
    "    unk_token  = []\n",
    "    df['tokens_encoded'] = df['CLIP_tokens']\n",
    "sos_token,eos_token,and_token, unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a808da84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_transforms: {'train': Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    <function <lambda> at 0x7face462dd08>\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "), 'val': Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    <function <lambda> at 0x7face462dd08>\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "), 'test': Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    <function <lambda> at 0x7face462dd08>\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      ")}\n",
      "Will use 348197 annotations for training.\n",
      "Will use 32011 annotations for validation.\n",
      "Will use 58927 annotations for testing.\n"
     ]
    }
   ],
   "source": [
    "df.tokens_encoded = df.tokens_encoded.apply(literal_eval)\n",
    "df.subject_encoded = df.subject_encoded.apply(literal_eval)\n",
    "df.predicate_encoded = df.predicate_encoded.apply(literal_eval)\n",
    "\n",
    "data_loaders, _ = preprocess_dataset(df, args,img_transform)\n",
    "print('Will use {} annotations for training.'.format(len(data_loaders['train'].dataset)))\n",
    "print('Will use {} annotations for validation.'.format(len(data_loaders['val'].dataset)))\n",
    "print('Will use {} annotations for testing.'.format(len(data_loaders['test'].dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1738b002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Index(['image_files', 'tokens_encoded', 'subject_encoded',\n",
      "       'predicate_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "working_data_loader = data_loaders[args_val.split]\n",
    "if args_val.max_utterance_len is None:\n",
    "    # use the maximum length in the underlying split.\n",
    "    def utterance_len(tokens, eos_token=eos_token):\n",
    "        return np.where(np.asarray(tokens) == eos_token)[0][0] -1 # -1 to remove sos\n",
    "    args_val.max_utterance_len = working_data_loader.dataset.tokens_encoded.apply(utterance_len).max()\n",
    "    print(args_val.max_utterance_len)\n",
    "annotate_loader = grounding_dataset_per_image_dummy(working_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1887bcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Describe model\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:\" + str(args.gpu)) # CHECK HERE\n",
    "    \n",
    "model = idcmodel(args.backboneVisEnc,args.image_resolution,\n",
    "                args.context_length,args.vocab_size,sos_token,eos_token,\n",
    "                args.transformer_heads,args.transformer_layers,\n",
    "                args.droprate)\n",
    "\n",
    "loaded_epoch = load_state_dicts(args_val.speaker_checkpoint, map_location='cpu', model=model)\n",
    "model.to(device)\n",
    "loaded_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3ae0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { \"sampling_rule\": \"beam\",\"temperature\": 1.0,\"beam_size\": 1,'max_utterance_len':63, \n",
    "          'drop_unk':True, 'drop_bigrams':True}\n",
    "final_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265f1d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with configuration:  {'sampling_rule': 'beam', 'temperature': 1.0, 'beam_size': 1, 'max_utterance_len': 63, 'drop_unk': True, 'drop_bigrams': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5497/5497 [4:31:46<00:00,  2.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Sampling with configuration: ', config)\n",
    "\n",
    "if args.random_seed != -1:\n",
    "    set_seed(args.random_seed)\n",
    "\n",
    "gen_df = versatile_caption_sampler(model,modeltype, annotate_loader,vocab,\n",
    "                                                    device, sos_token,eos_token,and_token, unk_token,\n",
    "                                                    args.vocab_size,**config)\n",
    "    \n",
    "final_results.append([config, gen_df])\n",
    "print('Done.')\n",
    "pickle_data(args_val.out_file, final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e12f8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_style</th>\n",
       "      <th>painting</th>\n",
       "      <th>captions_predicted</th>\n",
       "      <th>LC_predicted</th>\n",
       "      <th>IdC_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>robert-campin_saint-veronica-displaying-the-su...</td>\n",
       "      <td>the man looks like he is in a sword</td>\n",
       "      <td>the man in the painting looks sad and the colo...</td>\n",
       "      <td>the man looks like he is in a sword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>william-merritt-chase_portrait-of-harriet-hubb...</td>\n",
       "      <td>the woman looks like she is been a lot of her ...</td>\n",
       "      <td>the woman 's face is quite lovely and she is w...</td>\n",
       "      <td>the woman looks like she is been a lot of her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>willard-metcalf_passing-summer</td>\n",
       "      <td>the bright colors and blue make it look like a...</td>\n",
       "      <td>the bright colors and greens of the trees in t...</td>\n",
       "      <td>the bright colors and blue make it look like a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expressionism</td>\n",
       "      <td>salvador-dali_filius-prodigus-1964</td>\n",
       "      <td>the woman looks like she is trying to be a man</td>\n",
       "      <td>the man is naked and the woman is very arousing</td>\n",
       "      <td>the woman looks like she is trying to be a man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>ilya-mashkov_bakhchisarai-khan-s-palace-1925</td>\n",
       "      <td>the bright colors and blue of the building loo...</td>\n",
       "      <td>the colors are bright and the scene is very ca...</td>\n",
       "      <td>the bright colors and blue of the building loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>Expressionism</td>\n",
       "      <td>toyen_a-girl-face-with-gentian</td>\n",
       "      <td>the woman looks like she is in the sky</td>\n",
       "      <td>the woman 's face is very sad and the colors a...</td>\n",
       "      <td>the woman looks like she is in the sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>Expressionism</td>\n",
       "      <td>zinaida-serebriakova_england-1953</td>\n",
       "      <td>the sky looks like a storm is coming to the gr...</td>\n",
       "      <td>the wide open field and the sky is very peaceful</td>\n",
       "      <td>the sky looks like a storm is coming to the gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>lucas-cranach-the-elder_katharina-luther-1529</td>\n",
       "      <td>the woman looks like she is wearing a secret</td>\n",
       "      <td>the woman 's facial expression is hilarious an...</td>\n",
       "      <td>the woman looks like she is wearing a secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>hieronymus-bosch_haywain-1500-3</td>\n",
       "      <td>the man in the painting looks like he is in pain</td>\n",
       "      <td>the people are all interacting with the colors...</td>\n",
       "      <td>the man in the painting looks like he is in pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>lucas-cranach-the-elder_sleeping-nymph-of-the-...</td>\n",
       "      <td>the woman looks like she is relaxed and the river</td>\n",
       "      <td>the woman is naked and the river is very relaxed</td>\n",
       "      <td>the woman looks like she is relaxed and the river</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5497 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 art_style                                           painting  \\\n",
       "0     Northern_Renaissance  robert-campin_saint-veronica-displaying-the-su...   \n",
       "1            Impressionism  william-merritt-chase_portrait-of-harriet-hubb...   \n",
       "2            Impressionism                     willard-metcalf_passing-summer   \n",
       "3            Expressionism                 salvador-dali_filius-prodigus-1964   \n",
       "4            Impressionism       ilya-mashkov_bakhchisarai-khan-s-palace-1925   \n",
       "...                    ...                                                ...   \n",
       "5492         Expressionism                     toyen_a-girl-face-with-gentian   \n",
       "5493         Expressionism                  zinaida-serebriakova_england-1953   \n",
       "5494  Northern_Renaissance      lucas-cranach-the-elder_katharina-luther-1529   \n",
       "5495  Northern_Renaissance                    hieronymus-bosch_haywain-1500-3   \n",
       "5496  Northern_Renaissance  lucas-cranach-the-elder_sleeping-nymph-of-the-...   \n",
       "\n",
       "                                     captions_predicted  \\\n",
       "0                   the man looks like he is in a sword   \n",
       "1     the woman looks like she is been a lot of her ...   \n",
       "2     the bright colors and blue make it look like a...   \n",
       "3        the woman looks like she is trying to be a man   \n",
       "4     the bright colors and blue of the building loo...   \n",
       "...                                                 ...   \n",
       "5492             the woman looks like she is in the sky   \n",
       "5493  the sky looks like a storm is coming to the gr...   \n",
       "5494       the woman looks like she is wearing a secret   \n",
       "5495   the man in the painting looks like he is in pain   \n",
       "5496  the woman looks like she is relaxed and the river   \n",
       "\n",
       "                                           LC_predicted  \\\n",
       "0     the man in the painting looks sad and the colo...   \n",
       "1     the woman 's face is quite lovely and she is w...   \n",
       "2     the bright colors and greens of the trees in t...   \n",
       "3       the man is naked and the woman is very arousing   \n",
       "4     the colors are bright and the scene is very ca...   \n",
       "...                                                 ...   \n",
       "5492  the woman 's face is very sad and the colors a...   \n",
       "5493   the wide open field and the sky is very peaceful   \n",
       "5494  the woman 's facial expression is hilarious an...   \n",
       "5495  the people are all interacting with the colors...   \n",
       "5496   the woman is naked and the river is very relaxed   \n",
       "\n",
       "                                          IdC_predicted  \n",
       "0                   the man looks like he is in a sword  \n",
       "1     the woman looks like she is been a lot of her ...  \n",
       "2     the bright colors and blue make it look like a...  \n",
       "3        the woman looks like she is trying to be a man  \n",
       "4     the bright colors and blue of the building loo...  \n",
       "...                                                 ...  \n",
       "5492             the woman looks like she is in the sky  \n",
       "5493  the sky looks like a storm is coming to the gr...  \n",
       "5494       the woman looks like she is wearing a secret  \n",
       "5495   the man in the painting looks like he is in pain  \n",
       "5496  the woman looks like she is relaxed and the river  \n",
       "\n",
       "[5497 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e1656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
