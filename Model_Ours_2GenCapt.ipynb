{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060cc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\"\n",
    "#### Code adapted from the source code of ArtEmis dataset paper\n",
    "####################################################################\n",
    "Training a neural-speaker.\n",
    "\n",
    "The MIT License (MIT)\n",
    "Originally created at 6/16/20, for Python 3.x\n",
    "Copyright (c) 2021 Panos Achlioptas (ai.stanford.edu/~optas) & Stanford Geometric Computing Lab\n",
    "####################################################################\n",
    "\"\"\"\n",
    "import pprint\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from torch import nn\n",
    "from termcolor import colored\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model.argument import parse_test_speaker_arguments,set_seed\n",
    "from model.datasets import preprocess_dataset_capGen,IdCDataset\n",
    "\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from model.func_test import read_saved_args,grounding_dataset_per_image_dummy,versatile_caption_sampler\n",
    "from model.func_test import pickle_data\n",
    "\n",
    "from model.func_train import load_state_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3d67cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters Specified:\n",
      "{'drop_bigrams': True,\n",
      " 'drop_unk': True,\n",
      " 'gpu': '0',\n",
      " 'img_dir': '',\n",
      " 'max_utterance_len': None,\n",
      " 'out_file': 'output/CLIPViTB16_full/fullDB_test.pkl',\n",
      " 'out_file_full': None,\n",
      " 'random_seed': 2021,\n",
      " 'sampling_config_file': 'None',\n",
      " 'speaker_checkpoint': 'output/CLIPViTB16_full/checkpoints/best_model.pt',\n",
      " 'speaker_saved_args': 'output/CLIPViTB16_full/config.json.txt',\n",
      " 'split': 'test'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelname = 'CLIPViTB16_full' #'CLIPViTB16_full','CLIPViTB16_woSG','INRN34_full','INRN34_woSG','INViTB16_full','INViTB16_woSG'\n",
    "\n",
    "model_dir = f'output/{modelname}'\n",
    "outputfile = osp.join(model_dir,'fullDB_test.pkl')\n",
    "\n",
    "args_val = parse_test_speaker_arguments(\n",
    "        ['-speaker-saved-args',osp.join(model_dir,'config.json.txt'),\n",
    "         '-speaker-checkpoint',osp.join(model_dir,'checkpoints/best_model.pt'),#best_model.pt model_epoch_20.pt last_model\n",
    "         '-out-file',outputfile,\n",
    "         '-img-dir', '',\n",
    "         '--sampling-config-file', None,\n",
    "         '--split', 'test',\n",
    "         '--gpu','0']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5088945f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FreezeCase': 0,\n",
      " 'accum_iter': 2,\n",
      " 'backboneVisEnc': 'ViTB16',\n",
      " 'batch_size': 32,\n",
      " 'context_length': 65,\n",
      " 'data_dir': '../Dataset/ArtEmis/ArtEmis_IdC',\n",
      " 'debug': False,\n",
      " 'droprate': 0.0,\n",
      " 'gpu': '0',\n",
      " 'image_resolution': 224,\n",
      " 'img_dir': '../Dataset/ArtEmis/ArtEmis_IdC/Images/CLIP_224',\n",
      " 'lr_others': 0.001,\n",
      " 'lr_patience': 2,\n",
      " 'lr_textEnc': 0.001,\n",
      " 'lr_visEnc': 1e-07,\n",
      " 'max_epochs': 200,\n",
      " 'modeltype': 'full',\n",
      " 'output_dir': 'output2/CLIPViTB16_full',\n",
      " 'random_seed': 2021,\n",
      " 'save_each_epoch': False,\n",
      " 'train_patience': 5,\n",
      " 'transformer_heads': 8,\n",
      " 'transformer_layers': 8,\n",
      " 'use_timestamp': False,\n",
      " 'use_vocabFAM': True,\n",
      " 'vocab_size': 10506}\n"
     ]
    }
   ],
   "source": [
    "args = read_saved_args(args_val.speaker_saved_args)\n",
    "modeltype = args.modeltype \n",
    "use_vocabFAM = args.use_vocabFAM\n",
    "print(pprint.pformat(vars(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acceaa23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100393 captions!!!\n"
     ]
    }
   ],
   "source": [
    "## Load dataset\n",
    "file_name = 'ArtEmis_IdCI.csv'\n",
    "df = pd.read_csv(osp.join(args.data_dir, file_name))\n",
    "print(f'Loaded {len(df)} captions!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc921a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'full': \n",
    "    from model.model import fullArc as idcmodel\n",
    "elif modeltype == 'woSG': \n",
    "    from model.model import woSGArc as idcmodel \n",
    "else:\n",
    "    raise ValueError(f\"Do not support modeltype = {modeltype}!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d123f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 30, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_vocabFAM:\n",
    "    from model.vocabulary import Vocabulary\n",
    "    from model.func_test import get_highest_prob_capt as get_highest_prob_capt\n",
    "    vocab = Vocabulary.load(osp.join(args.data_dir, 'ArtEmis_IdCI_Vocab.pkl'))\n",
    "    eos_token = 2\n",
    "    sos_token = 1\n",
    "    and_token = vocab('and')\n",
    "    unk_token  = vocab.unk\n",
    "else: # Use original vocabulary of CLIP\n",
    "    from model.clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "    from model.func_test import get_highest_prob_capt_CLIP as get_highest_prob_capt\n",
    "    vocab = _Tokenizer()\n",
    "    eos_token = args.vocab_size-1 # eos_token is the last number\n",
    "    sos_token = args.vocab_size-2 #sos_token is the last second number\n",
    "    and_token = vocab.encode('and')[0]\n",
    "    unk_token  = []\n",
    "    df['tokens_encoded'] = df['CLIP_tokens']\n",
    "sos_token,eos_token,and_token, unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a808da84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use 75509 annotations for training.\n",
      "Will use 9000 annotations for validation.\n",
      "Will use 15884 annotations for testing.\n"
     ]
    }
   ],
   "source": [
    "df.tokens_encoded = df.tokens_encoded.apply(literal_eval)\n",
    "df.subject_encoded = df.subject_encoded.apply(literal_eval)\n",
    "df.predicate_encoded = df.predicate_encoded.apply(literal_eval)\n",
    "\n",
    "data_loaders, _ = preprocess_dataset_capGen(df, args)\n",
    "print('Will use {} annotations for training.'.format(len(data_loaders['train'].dataset)))\n",
    "print('Will use {} annotations for validation.'.format(len(data_loaders['val'].dataset)))\n",
    "print('Will use {} annotations for testing.'.format(len(data_loaders['test'].dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1738b002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Index(['image_files', 'tokens_encoded', 'subject_encoded',\n",
      "       'predicate_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "working_data_loader = data_loaders[args_val.split]\n",
    "if args_val.max_utterance_len is None:\n",
    "    # use the maximum length in the underlying split.\n",
    "    def utterance_len(tokens, eos_token=eos_token):\n",
    "        return np.where(np.asarray(tokens) == eos_token)[0][0] -1 # -1 to remove sos\n",
    "    args_val.max_utterance_len = working_data_loader.dataset.tokens_encoded.apply(utterance_len).max()\n",
    "    print(args_val.max_utterance_len)\n",
    "annotate_loader = grounding_dataset_per_image_dummy(working_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1887bcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Describe model\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:\" + str(args.gpu))\n",
    "    \n",
    "model = idcmodel(args.backboneVisEnc,args.image_resolution,\n",
    "                args.context_length,args.vocab_size,sos_token,eos_token,\n",
    "                args.transformer_heads,args.transformer_layers,\n",
    "                args.droprate)\n",
    "\n",
    "loaded_epoch = load_state_dicts(args_val.speaker_checkpoint, map_location='cpu', model=model)\n",
    "model.to(device)\n",
    "loaded_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ae0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { \"sampling_rule\": \"beam\",\"temperature\": 1.0,\"beam_size\": 1,'max_utterance_len':63, \n",
    "          'drop_unk':True, 'drop_bigrams':True}\n",
    "final_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265f1d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with configuration:  {'sampling_rule': 'beam', 'temperature': 1.0, 'beam_size': 1, 'max_utterance_len': 63, 'drop_unk': True, 'drop_bigrams': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2497/2497 [04:52<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Sampling with configuration: ', config)\n",
    "\n",
    "if args.random_seed != -1:\n",
    "    set_seed(args.random_seed)\n",
    "\n",
    "df = versatile_caption_sampler(model,modeltype, annotate_loader,vocab,\n",
    "                                                    device, sos_token,eos_token,and_token, unk_token,\n",
    "                                                    args.vocab_size,**config)\n",
    "    \n",
    "final_results.append([config, df])\n",
    "print('Done.')\n",
    "pickle_data(args_val.out_file, final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad95b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_style</th>\n",
       "      <th>painting</th>\n",
       "      <th>captions_predicted</th>\n",
       "      <th>prefs_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>robert-campin_saint-veronica-displaying-the-su...</td>\n",
       "      <td>the woman looks like a jester since and is a red</td>\n",
       "      <td>the woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>william-merritt-chase_portrait-of-harriet-hubb...</td>\n",
       "      <td>the woman looks like she is wearing a lot</td>\n",
       "      <td>the woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>willard-metcalf_passing-summer</td>\n",
       "      <td>the colors are bright and remind me of a summer</td>\n",
       "      <td>the colors are bright and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expressionism</td>\n",
       "      <td>salvador-dali_filius-prodigus-1964</td>\n",
       "      <td>the woman looks like she is in pain and the ma...</td>\n",
       "      <td>the woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>ilya-mashkov_bakhchisarai-khan-s-palace-1925</td>\n",
       "      <td>the blue sky looks like a beautiful place to t...</td>\n",
       "      <td>the blue sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Post_Impressionism</td>\n",
       "      <td>vincent-van-gogh_standing-female-nude-seen-fro...</td>\n",
       "      <td>the woman looks like she is in a mermaid</td>\n",
       "      <td>the woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Impressionism</td>\n",
       "      <td>gustave-caillebotte_the-garden</td>\n",
       "      <td>the flowers look like they are in a nice</td>\n",
       "      <td>the flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Northern_Renaissance</td>\n",
       "      <td>hieronymus-bosch_triptych-of-last-judgement</td>\n",
       "      <td>the man looks like he is about to die</td>\n",
       "      <td>the man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Symbolism</td>\n",
       "      <td>gustave-moreau_the-unicorns</td>\n",
       "      <td>the women look like they are having fun and th...</td>\n",
       "      <td>the women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>Expressionism</td>\n",
       "      <td>lucian-freud_lawrence-gowing</td>\n",
       "      <td>the man looks like he is been clawed and has a...</td>\n",
       "      <td>the man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 art_style                                           painting  \\\n",
       "0     Northern_Renaissance  robert-campin_saint-veronica-displaying-the-su...   \n",
       "1            Impressionism  william-merritt-chase_portrait-of-harriet-hubb...   \n",
       "2            Impressionism                     willard-metcalf_passing-summer   \n",
       "3            Expressionism                 salvador-dali_filius-prodigus-1964   \n",
       "4            Impressionism       ilya-mashkov_bakhchisarai-khan-s-palace-1925   \n",
       "...                    ...                                                ...   \n",
       "2492    Post_Impressionism  vincent-van-gogh_standing-female-nude-seen-fro...   \n",
       "2493         Impressionism                     gustave-caillebotte_the-garden   \n",
       "2494  Northern_Renaissance        hieronymus-bosch_triptych-of-last-judgement   \n",
       "2495             Symbolism                        gustave-moreau_the-unicorns   \n",
       "2496         Expressionism                       lucian-freud_lawrence-gowing   \n",
       "\n",
       "                                     captions_predicted  \\\n",
       "0      the woman looks like a jester since and is a red   \n",
       "1             the woman looks like she is wearing a lot   \n",
       "2       the colors are bright and remind me of a summer   \n",
       "3     the woman looks like she is in pain and the ma...   \n",
       "4     the blue sky looks like a beautiful place to t...   \n",
       "...                                                 ...   \n",
       "2492           the woman looks like she is in a mermaid   \n",
       "2493           the flowers look like they are in a nice   \n",
       "2494              the man looks like he is about to die   \n",
       "2495  the women look like they are having fun and th...   \n",
       "2496  the man looks like he is been clawed and has a...   \n",
       "\n",
       "                prefs_predicted  \n",
       "0                     the woman  \n",
       "1                     the woman  \n",
       "2     the colors are bright and  \n",
       "3                     the woman  \n",
       "4                  the blue sky  \n",
       "...                         ...  \n",
       "2492                  the woman  \n",
       "2493                the flowers  \n",
       "2494                    the man  \n",
       "2495                  the women  \n",
       "2496                    the man  \n",
       "\n",
       "[2497 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8ab11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
