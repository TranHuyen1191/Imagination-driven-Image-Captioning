{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of caption sets in the test set: 1699\n"
     ]
    }
   ],
   "source": [
    "## Prepare the  dataset (merge it with the emotion-histograms.)\n",
    "datasetname = 'COCO' #ArtEmis, Flickr30K,  VizWiz, COCO\n",
    "\n",
    "if datasetname == 'ArtEmis':\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdC/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/{datasetname}_IdC/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "    df = df[df.split=='test']\n",
    "else:\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print('Number of caption sets in the test set:', len(df))\n",
    "df.img_files = [osp.join(img_dir,imgfile) for imgfile in df.img_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['captSet_text'] = df['captSet_text'].apply(literal_eval)\n",
    "df['refCaptSet'] = df['refCaptSet'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMURF.smurf.eval import preprocess,smurf_eval_captions\n",
    "from SMURF.smurf.system_analysis import smurf_system_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing SPARCS score...\n",
      "Mean SPARCS score: 0.097. Computed in 2.36 seconds.\n",
      "computing MIMA score...\n",
      "Mean MIMA score: 0.464. Computed in 10.01 seconds.\n",
      "computing SPURTS score...\n",
      "Mean SPURTS score: 0.426. Computed in 6.88 seconds.\n",
      "computing SMURF score...\n",
      "Mean SMURF score: -0.739. Computed in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "no_imgs =len(df)\n",
    "cands = []\n",
    "refs = []\n",
    "for _,row in df.iterrows():\n",
    "    refs_processed = [preprocess(ref) for ref in row['refCaptSet']]\n",
    "    for cand in row['captSet_text']:\n",
    "        cands.append(preprocess(cand))\n",
    "        refs.append(refs_processed)\n",
    "meta_scorer = smurf_eval_captions(refs, cands, fuse=True)\n",
    "scores = meta_scorer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMURF = np.array(scores['SMURF']).reshape([-1,len(row['captSet_text'])])\n",
    "SPURTS = np.array(scores['SPURTS']).reshape([-1,len(row['captSet_text'])])\n",
    "SPARCS = np.array(scores['SPARCS']).reshape([-1,len(row['captSet_text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: COCO , Number of caption sets: 1699\n",
      "SMURF\n",
      "Accuracy at errType=1:583/1699= 0.3431430253090053\n",
      "Accuracy at errType=2:372/1699= 0.21895232489699823\n",
      "Accuracy at errType=3:301/1699= 0.17716303708063566\n",
      "Accuracy for all types:1256/5097= 0.24641946242887974\n",
      "Dataset: COCO , Number of caption sets: 1699\n",
      "SPURTS\n",
      "Accuracy at errType=1:652/1699= 0.3837551500882872\n",
      "Accuracy at errType=2:764/1699= 0.4496762801648028\n",
      "Accuracy at errType=3:1155/1699= 0.6798116539140671\n",
      "Accuracy for all types:2571/5097= 0.5044143613890524\n",
      "Dataset: COCO , Number of caption sets: 1699\n",
      "SPARCS\n",
      "Accuracy at errType=1:333/1699= 0.19599764567392583\n",
      "Accuracy at errType=2:272/1699= 0.16009417304296644\n",
      "Accuracy at errType=3:197/1699= 0.11595055915244261\n",
      "Accuracy for all types:802/5097= 0.1573474592897783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "no_errType = 3\n",
    "cnt_corr_all = 0\n",
    "cnt_incorr_all = 0\n",
    "print(\"Dataset:\",datasetname,\", Number of caption sets:\",no_imgs)\n",
    "print(\"SMURF\")\n",
    "for errType in range(1,no_errType+1):\n",
    "    cnt_corr = 0\n",
    "    cnt_incorr = 0\n",
    "    for sim in SMURF:\n",
    "        if sim[0] > sim[errType]:\n",
    "            cnt_corr +=1\n",
    "            cnt_corr_all +=1\n",
    "        else:\n",
    "            cnt_incorr +=1\n",
    "            cnt_incorr_all +=1\n",
    "    print(f\"Accuracy at errType={errType}:{cnt_corr}/{cnt_corr+cnt_incorr}=\",cnt_corr/(cnt_corr+cnt_incorr))\n",
    "\n",
    "print(f\"Accuracy for all types:{cnt_corr_all}/{cnt_corr_all+cnt_incorr_all}=\",cnt_corr_all/(cnt_corr_all+cnt_incorr_all))\n",
    "\n",
    "cnt_corr_all = 0\n",
    "cnt_incorr_all = 0\n",
    "print(\"Dataset:\",datasetname,\", Number of caption sets:\",no_imgs)\n",
    "print(\"SPURTS\")\n",
    "for errType in range(1,no_errType+1):\n",
    "    cnt_corr = 0\n",
    "    cnt_incorr = 0\n",
    "    for sim in SPURTS:\n",
    "        if sim[0] > sim[errType]:\n",
    "            cnt_corr +=1\n",
    "            cnt_corr_all +=1\n",
    "        else:\n",
    "            cnt_incorr +=1\n",
    "            cnt_incorr_all +=1\n",
    "    print(f\"Accuracy at errType={errType}:{cnt_corr}/{cnt_corr+cnt_incorr}=\",cnt_corr/(cnt_corr+cnt_incorr))\n",
    "\n",
    "print(f\"Accuracy for all types:{cnt_corr_all}/{cnt_corr_all+cnt_incorr_all}=\",cnt_corr_all/(cnt_corr_all+cnt_incorr_all))\n",
    "\n",
    "cnt_corr_all = 0\n",
    "cnt_incorr_all = 0\n",
    "print(\"Dataset:\",datasetname,\", Number of caption sets:\",no_imgs)\n",
    "print(\"SPARCS\")\n",
    "for errType in range(1,no_errType+1):\n",
    "    cnt_corr = 0\n",
    "    cnt_incorr = 0\n",
    "    for sim in SPARCS:\n",
    "        if sim[0] > sim[errType]:\n",
    "            cnt_corr +=1\n",
    "            cnt_corr_all +=1\n",
    "        else:\n",
    "            cnt_incorr +=1\n",
    "            cnt_incorr_all +=1\n",
    "    print(f\"Accuracy at errType={errType}:{cnt_corr}/{cnt_corr+cnt_incorr}=\",cnt_corr/(cnt_corr+cnt_incorr))\n",
    "\n",
    "print(f\"Accuracy for all types:{cnt_corr_all}/{cnt_corr_all+cnt_incorr_all}=\",cnt_corr_all/(cnt_corr_all+cnt_incorr_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-7c9cb674b986>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-7c9cb674b986>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Dataset: COCO , Number of caption sets: 1699\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Dataset: COCO , Number of caption sets: 1699\n",
    "SMURF\n",
    "Accuracy at errType=1:583/1699= 0.3431430253090053\n",
    "Accuracy at errType=2:372/1699= 0.21895232489699823\n",
    "Accuracy at errType=3:301/1699= 0.17716303708063566\n",
    "Accuracy for all types:1256/5097= 0.24641946242887974\n",
    "Dataset: COCO , Number of caption sets: 1699\n",
    "SPURTS\n",
    "Accuracy at errType=1:652/1699= 0.3837551500882872\n",
    "Accuracy at errType=2:764/1699= 0.4496762801648028\n",
    "Accuracy at errType=3:1155/1699= 0.6798116539140671\n",
    "Accuracy for all types:2571/5097= 0.5044143613890524\n",
    "Dataset: COCO , Number of caption sets: 1699\n",
    "SPARCS\n",
    "Accuracy at errType=1:333/1699= 0.19599764567392583\n",
    "Accuracy at errType=2:272/1699= 0.16009417304296644\n",
    "Accuracy at errType=3:197/1699= 0.11595055915244261\n",
    "Accuracy for all types:802/5097= 0.1573474592897783\n",
    "    \n",
    "Dataset: VizWiz , Number of caption sets: 1160\n",
    "SMURF\n",
    "Accuracy at errType=1:310/1160= 0.2672413793103448\n",
    "Accuracy at errType=2:196/1160= 0.16896551724137931\n",
    "Accuracy at errType=3:83/1160= 0.07155172413793104\n",
    "Accuracy for all types:589/3480= 0.1692528735632184\n",
    "Dataset: VizWiz , Number of caption sets: 1160\n",
    "SPURTS\n",
    "Accuracy at errType=1:491/1160= 0.4232758620689655\n",
    "Accuracy at errType=2:562/1160= 0.4844827586206897\n",
    "Accuracy at errType=3:821/1160= 0.7077586206896552\n",
    "Accuracy for all types:1874/3480= 0.5385057471264367\n",
    "Dataset: VizWiz , Number of caption sets: 1160\n",
    "SPARCS\n",
    "Accuracy at errType=1:41/1160= 0.0353448275862069\n",
    "Accuracy at errType=2:24/1160= 0.020689655172413793\n",
    "Accuracy at errType=3:9/1160= 0.007758620689655172\n",
    "Accuracy for all types:74/3480= 0.021264367816091954\n",
    "    \n",
    "Dataset: Flickr30K , Number of caption sets: 595\n",
    "SMURF\n",
    "Accuracy at errType=1:198/595= 0.33277310924369746\n",
    "Accuracy at errType=2:121/595= 0.20336134453781513\n",
    "Accuracy at errType=3:58/595= 0.09747899159663866\n",
    "Accuracy for all types:377/1785= 0.21120448179271709\n",
    "Dataset: Flickr30K , Number of caption sets: 595\n",
    "SPURTS\n",
    "Accuracy at errType=1:253/595= 0.42521008403361343\n",
    "Accuracy at errType=2:253/595= 0.42521008403361343\n",
    "Accuracy at errType=3:424/595= 0.7126050420168067\n",
    "Accuracy for all types:930/1785= 0.5210084033613446\n",
    "Dataset: Flickr30K , Number of caption sets: 595\n",
    "SPARCS\n",
    "Accuracy at errType=1:28/595= 0.047058823529411764\n",
    "Accuracy at errType=2:27/595= 0.0453781512605042\n",
    "Accuracy at errType=3:15/595= 0.025210084033613446\n",
    "Accuracy for all types:70/1785= 0.0392156862745098\n",
    "    \n",
    "Dataset: ArtEmis , Number of caption sets: 15884\n",
    "SMURF\n",
    "Accuracy at errType=1:8765/15884= 0.55181314530345\n",
    "Accuracy at errType=2:10184/15884= 0.6411483253588517\n",
    "Accuracy at errType=3:9016/15884= 0.56761521027449\n",
    "Accuracy for all types:27965/47652= 0.5868588936455973\n",
    "Dataset: ArtEmis , Number of caption sets: 15884\n",
    "SPURTS\n",
    "Accuracy at errType=1:5818/15884= 0.3662805338705616\n",
    "Accuracy at errType=2:9416/15884= 0.592797783933518\n",
    "Accuracy at errType=3:11336/15884= 0.7136741374968522\n",
    "Accuracy for all types:26570/47652= 0.5575841517669773\n",
    "Dataset: ArtEmis , Number of caption sets: 15884\n",
    "SPARCS\n",
    "Accuracy at errType=1:11952/15884= 0.7524553009317553\n",
    "Accuracy at errType=2:10160/15884= 0.63963737093931\n",
    "Accuracy at errType=3:3899/15884= 0.24546713674137496\n",
    "Accuracy for all types:26011/47652= 0.54585326953748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
