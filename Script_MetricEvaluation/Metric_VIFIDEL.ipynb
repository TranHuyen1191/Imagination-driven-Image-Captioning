{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pdb\n",
    "import clip \n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of caption sets in the test set: 1699\n"
     ]
    }
   ],
   "source": [
    "## Prepare the  dataset (merge it with the emotion-histograms.)\n",
    "datasetname = 'COCO' #ArtEmis, Flickr30K,  VizWiz, COCO\n",
    "\n",
    "if datasetname == 'ArtEmis':\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdC/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/{datasetname}_IdC/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "    df = df[df.split=='test']\n",
    "else:\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print('Number of caption sets in the test set:', len(df))\n",
    "df['captSet_CLIP_tokens'] = df['captSet_CLIP_tokens'].apply(literal_eval)\n",
    "df.img_files = [osp.join(img_dir,imgfile) for imgfile in df.img_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using source code of vifidel https://github.com/ImperialNLP/vifidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['captSet_text'] = df['captSet_text'].apply(literal_eval)\n",
    "data_path = '../Dataset/genome/1600-400-20'\n",
    "\n",
    "# Load classes\n",
    "classes = ['__background__']\n",
    "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        classes.append(object.split(',')[0].lower().strip())\n",
    "score_thresh = 0.3\n",
    "no_errType = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from pyemd import emd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('vifidel/data/GoogleNews-vectors-negative300.bin.gz',binary=True) \n",
    "vocab = word_vectors.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vifidel_scores = []\n",
    "\n",
    "for _,row in df.iterrows():\n",
    "    imgfeat_file = row['imgfeat_file']\n",
    "    captSet = row['captSet_text']\n",
    "    roi_feats = np.load(imgfeat_file, allow_pickle=True)\n",
    "    info = roi_feats['info'].item()\n",
    "    num_boxes = info['num_boxes']\n",
    "    objects_id = info['objects_id']\n",
    "    objects_conf = info['objects_conf']\n",
    "    objects = objects_id\n",
    "    detected_objs = []\n",
    "    for i in range(num_boxes):\n",
    "        if objects_conf[i] > score_thresh:\n",
    "            detected_objs.append(classes[objects[i]+1])\n",
    "    vifidel_score_captSet = []      \n",
    "    for i in range(no_errType+1): # natural and unnatural captions\n",
    "        desc = []\n",
    "        for w in captSet[i].split(' '):\n",
    "            if w in vocab:\n",
    "                desc.append(w)\n",
    "        desc = ' '.join(desc) \n",
    "        objs = ' '.join(detected_objs) \n",
    "        vc = CountVectorizer(stop_words='english').fit([objs, desc])\n",
    "        v_obj, v_desc = vc.transform([objs, desc])\n",
    "\n",
    "        v_obj = v_obj.toarray().ravel()\n",
    "        v_desc = v_desc.toarray().ravel()\n",
    "        wvoc = word_vectors[[w for w in vc.get_feature_names()]]\n",
    "        distance_matrix = euclidean_distances(wvoc)\n",
    "\n",
    "        if np.sum(distance_matrix) == 0.0:\n",
    "            score = float('inf')\n",
    "\n",
    "        else:\n",
    "            v_obj = v_obj.astype(np.double)\n",
    "            v_desc = v_desc.astype(np.double)\n",
    "            if v_obj.sum():\n",
    "                v_obj /= v_obj.sum()\n",
    "            if v_desc.sum():\n",
    "                v_desc /= v_desc.sum()\n",
    "\n",
    "            distance_matrix = distance_matrix.astype(np.double)\n",
    "            score = np.exp(-emd(v_obj, v_desc, distance_matrix))\n",
    "        vifidel_score_captSet.append(score)\n",
    "    vifidel_scores.append(vifidel_score_captSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: COCO , Number of caption sets: 1699\n",
      "Accuracy at errType=1:1478/1699= 0.8699234844025897\n",
      "Accuracy at errType=2:1134/1699= 0.6674514420247204\n",
      "Accuracy at errType=3:805/1699= 0.47380812242495585\n",
      "Accuracy for all types:3417/5097= 0.6703943496174221\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "no_errType = 3\n",
    "cnt_corr_all = 0\n",
    "cnt_incorr_all = 0\n",
    "print(\"Dataset:\",datasetname,\", Number of caption sets:\",len(vifidel_scores))\n",
    "for errType in range(1,no_errType+1):\n",
    "    cnt_corr = 0\n",
    "    cnt_incorr = 0\n",
    "    for sim in vifidel_scores:\n",
    "        if sim[0] > sim[errType]:\n",
    "            cnt_corr +=1\n",
    "            cnt_corr_all +=1\n",
    "        else:\n",
    "            cnt_incorr +=1\n",
    "            cnt_incorr_all +=1\n",
    "    print(f\"Accuracy at errType={errType}:{cnt_corr}/{cnt_corr+cnt_incorr}=\",cnt_corr/(cnt_corr+cnt_incorr))\n",
    "\n",
    "print(f\"Accuracy for all types:{cnt_corr_all}/{cnt_corr_all+cnt_incorr_all}=\",cnt_corr_all/(cnt_corr_all+cnt_incorr_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-411e85655a52>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-411e85655a52>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Dataset: COCO , Number of caption sets: 1699\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Dataset: COCO , Number of caption sets: 1699\n",
    "Accuracy at errType=1:1478/1699= 0.8699234844025897\n",
    "Accuracy at errType=2:1134/1699= 0.6674514420247204\n",
    "Accuracy at errType=3:805/1699= 0.47380812242495585\n",
    "Accuracy for all types:3417/5097= 0.6703943496174221\n",
    "    \n",
    "Dataset: VizWiz , Number of caption sets: 1160\n",
    "Accuracy at errType=1:755/1160= 0.6508620689655172\n",
    "Accuracy at errType=2:753/1160= 0.6491379310344828\n",
    "Accuracy at errType=3:411/1160= 0.3543103448275862\n",
    "Accuracy for all types:1919/3480= 0.5514367816091954\n",
    "\n",
    "Dataset: Flickr30K , Number of caption sets: 595\n",
    "Accuracy at errType=1:377/595= 0.6336134453781512\n",
    "Accuracy at errType=2:363/595= 0.6100840336134454\n",
    "Accuracy at errType=3:220/595= 0.3697478991596639\n",
    "Accuracy for all types:960/1785= 0.5378151260504201\n",
    "    \n",
    "Dataset: ArtEmis , Number of caption sets: 15884\n",
    "Accuracy at errType=1:9548/15884= 0.6011080332409973\n",
    "Accuracy at errType=2:9314/15884= 0.5863762276504659\n",
    "Accuracy at errType=3:5282/15884= 0.33253588516746413\n",
    "Accuracy for all types:24144/47652= 0.5066733820196424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK trends of scores as shown in Figure 5 in the paper\n",
    "## Not exactly the same with scores in the paper due to NO USE references\n",
    "objs_cases = ['person','person, dining-table','person, dining-table, umbrella, handbag, bottle',\n",
    "              'person, car, backpack, umbrella, handbag, bottle, dining-table, cup, fork, knife',\n",
    "             'person, car, backpack, umbrella, handbag, bottle, wine-glass, cup, fork, knife, spoon, bowl, broccoli, chair, dining-table']\n",
    "desc = 'a table full of people at the restaurant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04917496548339995\n",
      "0.190300261140906\n",
      "0.06650828873819793\n",
      "0.04373043400646706\n",
      "0.036058309582535475\n"
     ]
    }
   ],
   "source": [
    "for objs in objs_cases:    \n",
    "    vc = CountVectorizer(stop_words='english').fit([objs, desc])\n",
    "    v_obj, v_desc = vc.transform([objs, desc])\n",
    "\n",
    "    v_obj = v_obj.toarray().ravel()\n",
    "    v_desc = v_desc.toarray().ravel()\n",
    "    wvoc = word_vectors[[w for w in vc.get_feature_names()]]\n",
    "    distance_matrix = euclidean_distances(wvoc)\n",
    "\n",
    "    if np.sum(distance_matrix) == 0.0:\n",
    "        score = float('inf')\n",
    "\n",
    "    else:\n",
    "        v_obj = v_obj.astype(np.double)\n",
    "        v_desc = v_desc.astype(np.double)\n",
    "        if v_obj.sum():\n",
    "            v_obj /= v_obj.sum()\n",
    "        if v_desc.sum():\n",
    "            v_desc /= v_desc.sum()\n",
    "\n",
    "        distance_matrix = distance_matrix.astype(np.double)\n",
    "        score = np.exp(-emd(v_obj, v_desc, distance_matrix))\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
