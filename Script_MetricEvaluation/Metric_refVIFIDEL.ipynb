{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pdb\n",
    "import clip \n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of caption sets in the test set: 1699\n"
     ]
    }
   ],
   "source": [
    "## Prepare the  dataset (merge it with the emotion-histograms.)\n",
    "datasetname = 'COCO' #ArtEmis, Flickr30K,  VizWiz, COCO\n",
    "\n",
    "if datasetname == 'ArtEmis':\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdC/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/{datasetname}_IdC/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "    df = df[df.split=='test']\n",
    "else:\n",
    "    datafile = f'../Dataset/{datasetname}/{datasetname}_IdCII_3ErrType.csv'\n",
    "    img_dir = f\"../Dataset/{datasetname}/Images/rawImages\"\n",
    "    df = pd.read_csv(datafile)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print('Number of caption sets in the test set:', len(df))\n",
    "df['captSet_CLIP_tokens'] = df['captSet_CLIP_tokens'].apply(literal_eval)\n",
    "df.img_files = [osp.join(img_dir,imgfile) for imgfile in df.img_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using source code of vifidel https://github.com/ImperialNLP/vifidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['captSet_text'] = df['captSet_text'].apply(literal_eval)\n",
    "df['refCaptSet'] = df['refCaptSet'].apply(literal_eval)\n",
    "\n",
    "data_path = '../Dataset/genome/1600-400-20'\n",
    "\n",
    "# Load classes\n",
    "classes = ['__background__']\n",
    "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        classes.append(object.split(',')[0].lower().strip())\n",
    "score_thresh = 0.3\n",
    "no_errType = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from pyemd import emd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('vifidel/data/GoogleNews-vectors-negative300.bin.gz',binary=True) \n",
    "vocab = word_vectors.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vifidel_scores = []\n",
    "for _,row in df.iterrows():\n",
    "    imgfeat_file = row['imgfeat_file']\n",
    "    captSet = row['captSet_text']\n",
    "    refcaptSet = row['refCaptSet']\n",
    "    roi_feats = np.load(imgfeat_file, allow_pickle=True)\n",
    "    info = roi_feats['info'].item()\n",
    "    num_boxes = info['num_boxes']\n",
    "    objects_id = info['objects_id']\n",
    "    objects_conf = info['objects_conf']\n",
    "    objects = objects_id\n",
    "    detected_objs = []\n",
    "    for i in range(num_boxes):\n",
    "        if objects_conf[i] > score_thresh:\n",
    "            detected_objs.append(classes[objects[i]+1])\n",
    "    vifidel_score_captSet = [] \n",
    "    for i in range(no_errType+1): # natural and unnatural captions\n",
    "        desc = []\n",
    "        for w in captSet[i].split(' '): ## Excluding words not in vocab\n",
    "            if w in vocab:\n",
    "                desc.append(w)\n",
    "        desc = ' '.join(desc) \n",
    "        objs = ' '.join(detected_objs) \n",
    "        vc = CountVectorizer(stop_words='english').fit([objs, desc])\n",
    "        v_obj, v_desc = vc.transform([objs, desc])\n",
    "\n",
    "        v_obj = v_obj.toarray().ravel()\n",
    "        v_desc = v_desc.toarray().ravel()\n",
    "        wvoc = word_vectors[[w for w in vc.get_feature_names()]]\n",
    "        \n",
    "        if len(refcaptSet) ==0:\n",
    "            distance_matrix = euclidean_distances(wvoc)\n",
    "\n",
    "            if np.sum(distance_matrix) == 0.0:\n",
    "                score = float('inf')\n",
    "\n",
    "            else:\n",
    "                v_obj = v_obj.astype(np.double)\n",
    "                v_desc = v_desc.astype(np.double)\n",
    "                if v_obj.sum():\n",
    "                    v_obj /= v_obj.sum()\n",
    "                if v_desc.sum():\n",
    "                    v_desc /= v_desc.sum()\n",
    "\n",
    "                distance_matrix = distance_matrix.astype(np.double)\n",
    "                score = np.exp(-emd(v_obj, v_desc, distance_matrix))\n",
    "        else: ## Reference\n",
    "            weightsn = np.zeros(len(wvoc))\n",
    "            for r_ori in refcaptSet:\n",
    "                r = []\n",
    "                for w in r_ori.split(' '): ## Excluding words not in vocab\n",
    "                    if w in vocab:\n",
    "                        r.append(w)\n",
    "                r = ' '.join(r) \n",
    "                vr = CountVectorizer(stop_words='english').fit([r])\n",
    "                wvr = word_vectors[[w for w in vr.get_feature_names()]]\n",
    "                wts = (1. - cosine_similarity(wvoc, wvr).max(axis=1))\n",
    "                wts = np.array([w if np.sign(w) == 1 else 0. for w in wts]) / 2.\n",
    "                weightsn += wts\n",
    "\n",
    "            weights = weightsn / len(refcaptSet)\n",
    "\n",
    "\n",
    "            distance_matrix = np.zeros((len(wvoc), len(wvoc)), dtype=np.double)\n",
    "            for i, o in enumerate(vc.get_feature_names()):\n",
    "                for j, c in enumerate(vc.get_feature_names()):\n",
    "                    distance_matrix[i,j] = np.sqrt(np.sum(((weights[i] *\n",
    "                        word_vectors[o]) - (weights[j] *\n",
    "                            word_vectors[c]))**2))\n",
    "\n",
    "            if np.sum(distance_matrix) == 0.0:\n",
    "                score =  float('inf')\n",
    "            else:\n",
    "                v_obj = v_obj.astype(np.double)\n",
    "                v_desc = v_desc.astype(np.double)\n",
    "                if v_obj.sum():\n",
    "                    v_obj /= v_obj.sum()\n",
    "                if v_desc.sum():\n",
    "                    v_desc /= v_desc.sum()\n",
    "\n",
    "                distance_matrix = distance_matrix.astype(np.double)\n",
    "                # distance_matrix /= distance_matrix.max()\n",
    "                score = np.exp(-emd(v_obj, v_desc, distance_matrix))\n",
    "        \n",
    "        vifidel_score_captSet.append(score)\n",
    "    vifidel_scores.append(vifidel_score_captSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: COCO , Number of caption sets: 1699\n",
      "Accuracy at errType=1:1506/1699= 0.8864037669217186\n",
      "Accuracy at errType=2:1202/1699= 0.707474985285462\n",
      "Accuracy at errType=3:860/1699= 0.5061801059446733\n",
      "Accuracy for all types:3568/5097= 0.7000196193839513\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "no_errType = 3\n",
    "cnt_corr_all = 0\n",
    "cnt_incorr_all = 0\n",
    "print(\"Dataset:\",datasetname,\", Number of caption sets:\",len(vifidel_scores))\n",
    "for errType in range(1,no_errType+1):\n",
    "    cnt_corr = 0\n",
    "    cnt_incorr = 0\n",
    "    for sim in vifidel_scores:\n",
    "        if sim[0] > sim[errType]:\n",
    "            cnt_corr +=1\n",
    "            cnt_corr_all +=1\n",
    "        else:\n",
    "            cnt_incorr +=1\n",
    "            cnt_incorr_all +=1\n",
    "    print(f\"Accuracy at errType={errType}:{cnt_corr}/{cnt_corr+cnt_incorr}=\",cnt_corr/(cnt_corr+cnt_incorr))\n",
    "\n",
    "print(f\"Accuracy for all types:{cnt_corr_all}/{cnt_corr_all+cnt_incorr_all}=\",cnt_corr_all/(cnt_corr_all+cnt_incorr_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-1bd8056545ae>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-1bd8056545ae>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Dataset: COCO , Number of caption sets: 1699\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Dataset: COCO , Number of caption sets: 1699\n",
    "Accuracy at errType=1:1506/1699= 0.8864037669217186\n",
    "Accuracy at errType=2:1202/1699= 0.707474985285462\n",
    "Accuracy at errType=3:860/1699= 0.5061801059446733\n",
    "Accuracy for all types:3568/5097= 0.7000196193839513\n",
    "    \n",
    "Dataset: VizWiz , Number of caption sets: 1160\n",
    "Accuracy at errType=1:760/1160= 0.6551724137931034\n",
    "Accuracy at errType=2:759/1160= 0.6543103448275862\n",
    "Accuracy at errType=3:414/1160= 0.3568965517241379\n",
    "Accuracy for all types:1933/3480= 0.5554597701149425\n",
    "\n",
    "Dataset: Flickr30K , Number of caption sets: 595\n",
    "Accuracy at errType=1:384/595= 0.6453781512605042\n",
    "Accuracy at errType=2:369/595= 0.6201680672268908\n",
    "Accuracy at errType=3:225/595= 0.37815126050420167\n",
    "Accuracy for all types:978/1785= 0.5478991596638656\n",
    "\n",
    "Dataset: ArtEmis , Number of caption sets: 15884\n",
    "Accuracy at errType=1:11337/15884= 0.7137370939309997\n",
    "Accuracy at errType=2:10027/15884= 0.6312641651976832\n",
    "Accuracy at errType=3:4151/15884= 0.2613321581465626\n",
    "Accuracy for all types:25515/47652= 0.5354444724250819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
